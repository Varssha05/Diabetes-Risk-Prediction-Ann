{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TR6qs91ibo76",
        "outputId": "8e785541-d261-4aa5-eacc-f34eb523d41e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"catboost\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BVRyjnshb-2R",
        "outputId": "8628546d-59e4-40b8-f34e-6dd1553cb1e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>smoking_history</th>\n",
              "      <th>bmi</th>\n",
              "      <th>HbA1c_level</th>\n",
              "      <th>blood_glucose_level</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>never</td>\n",
              "      <td>25.19</td>\n",
              "      <td>6.6</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>No Info</td>\n",
              "      <td>27.32</td>\n",
              "      <td>6.6</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>never</td>\n",
              "      <td>27.32</td>\n",
              "      <td>5.7</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>current</td>\n",
              "      <td>23.45</td>\n",
              "      <td>5.0</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>current</td>\n",
              "      <td>21.14</td>\n",
              "      <td>4.8</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>No Info</td>\n",
              "      <td>27.32</td>\n",
              "      <td>6.2</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>Female</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>No Info</td>\n",
              "      <td>17.37</td>\n",
              "      <td>6.5</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>Male</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>former</td>\n",
              "      <td>27.83</td>\n",
              "      <td>5.7</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>Female</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>never</td>\n",
              "      <td>35.42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>Female</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>current</td>\n",
              "      <td>22.43</td>\n",
              "      <td>6.6</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
              "0      Female  81.0             0              1           never  25.19   \n",
              "1      Female  54.0             0              1         No Info  27.32   \n",
              "2        Male  28.0             0              1           never  27.32   \n",
              "3      Female  36.0             0              1         current  23.45   \n",
              "4        Male  76.0             1              1         current  21.14   \n",
              "...       ...   ...           ...            ...             ...    ...   \n",
              "99995  Female  81.0             0              1         No Info  27.32   \n",
              "99996  Female   2.0             0              1         No Info  17.37   \n",
              "99997    Male  66.0             0              1          former  27.83   \n",
              "99998  Female  24.0             0              1           never  35.42   \n",
              "99999  Female  57.0             0              1         current  22.43   \n",
              "\n",
              "       HbA1c_level  blood_glucose_level  diabetes  \n",
              "0              6.6                  141         0  \n",
              "1              6.6                   81         0  \n",
              "2              5.7                  158         0  \n",
              "3              5.0                  155         0  \n",
              "4              4.8                  155         0  \n",
              "...            ...                  ...       ...  \n",
              "99995          6.2                   91         0  \n",
              "99996          6.5                  111         0  \n",
              "99997          5.7                  155         0  \n",
              "99998          4.0                  111         0  \n",
              "99999          6.6                   91         0  \n",
              "\n",
              "[100000 rows x 9 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv(r\"E:\\Capstone Project 2 using vs code\\diabetes_prediction_dataset.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvS3KPvuVcrz"
      },
      "source": [
        "Checkinh Null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "ntQszLDjcLPK",
        "outputId": "43de82d4-1a32-4d8c-eb5c-dce401baf331"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender                 0\n",
              "age                    0\n",
              "hypertension           0\n",
              "heart_disease          0\n",
              "smoking_history        0\n",
              "bmi                    0\n",
              "HbA1c_level            0\n",
              "blood_glucose_level    0\n",
              "diabetes               0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SChdxvtgVfiG"
      },
      "source": [
        "Checking Duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w8akgVBcUjl",
        "outputId": "946c0788-1428-4fc5-9e00-7aa2a7f691eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(4504)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "T1NBFpcWcfuB",
        "outputId": "32c26d9f-e781-4b09-d2a1-5fa21501f3cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>smoking_history</th>\n",
              "      <th>bmi</th>\n",
              "      <th>HbA1c_level</th>\n",
              "      <th>blood_glucose_level</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>never</td>\n",
              "      <td>25.19</td>\n",
              "      <td>6.6</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>No Info</td>\n",
              "      <td>27.32</td>\n",
              "      <td>6.6</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>never</td>\n",
              "      <td>27.32</td>\n",
              "      <td>5.7</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>current</td>\n",
              "      <td>23.45</td>\n",
              "      <td>5.0</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>current</td>\n",
              "      <td>21.14</td>\n",
              "      <td>4.8</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99994</th>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>No Info</td>\n",
              "      <td>24.60</td>\n",
              "      <td>4.8</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>Female</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>No Info</td>\n",
              "      <td>17.37</td>\n",
              "      <td>6.5</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>Male</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>former</td>\n",
              "      <td>27.83</td>\n",
              "      <td>5.7</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>Female</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>never</td>\n",
              "      <td>35.42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>Female</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>current</td>\n",
              "      <td>22.43</td>\n",
              "      <td>6.6</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>95496 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
              "0      Female  81.0             0              1           never  25.19   \n",
              "1      Female  54.0             0              1         No Info  27.32   \n",
              "2        Male  28.0             0              1           never  27.32   \n",
              "3      Female  36.0             0              1         current  23.45   \n",
              "4        Male  76.0             1              1         current  21.14   \n",
              "...       ...   ...           ...            ...             ...    ...   \n",
              "99994  Female  36.0             0              1         No Info  24.60   \n",
              "99996  Female   2.0             0              1         No Info  17.37   \n",
              "99997    Male  66.0             0              1          former  27.83   \n",
              "99998  Female  24.0             0              1           never  35.42   \n",
              "99999  Female  57.0             0              1         current  22.43   \n",
              "\n",
              "       HbA1c_level  blood_glucose_level  diabetes  \n",
              "0              6.6                  141         0  \n",
              "1              6.6                   81         0  \n",
              "2              5.7                  158         0  \n",
              "3              5.0                  155         0  \n",
              "4              4.8                  155         0  \n",
              "...            ...                  ...       ...  \n",
              "99994          4.8                  145         0  \n",
              "99996          6.5                  111         0  \n",
              "99997          5.7                  155         0  \n",
              "99998          4.0                  111         0  \n",
              "99999          6.6                   91         0  \n",
              "\n",
              "[95496 rows x 9 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4dIUrEScGro",
        "outputId": "3f90c23d-1bed-4743-99d2-8aa3bf7b2c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 9 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   gender               100000 non-null  object \n",
            " 1   age                  100000 non-null  float64\n",
            " 2   hypertension         100000 non-null  int64  \n",
            " 3   heart_disease        100000 non-null  int64  \n",
            " 4   smoking_history      100000 non-null  object \n",
            " 5   bmi                  100000 non-null  float64\n",
            " 6   HbA1c_level          100000 non-null  float64\n",
            " 7   blood_glucose_level  100000 non-null  int64  \n",
            " 8   diabetes             100000 non-null  int64  \n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 6.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "thh_Im7icnlb",
        "outputId": "caa489c6-66cf-4d60-fd0d-05bf5fa7347d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "diabetes\n",
              "0    91500\n",
              "1     8500\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#chk for balancing or unbalanced data\n",
        "df['diabetes'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Y3r7SuwncuDm",
        "outputId": "ae867595-d0bd-42de-fb07-e6cf29687892"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='diabetes', ylabel='Count'>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.histplot(df,x='diabetes',kde=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTPj4ktnVz1r"
      },
      "source": [
        "Outlayers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Xb_wrKjrdlkx",
        "outputId": "e51f7450-9b8f-4299-d09f-5a81b25893a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='diabetes'>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.boxplot(df.diabetes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUz7DiGPdpS0",
        "outputId": "a8af81fa-5438-44bd-8bf6-667e7a3cc486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 9 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   gender               100000 non-null  int64  \n",
            " 1   age                  100000 non-null  float64\n",
            " 2   hypertension         100000 non-null  int64  \n",
            " 3   heart_disease        100000 non-null  int64  \n",
            " 4   smoking_history      100000 non-null  int64  \n",
            " 5   bmi                  100000 non-null  float64\n",
            " 6   HbA1c_level          100000 non-null  float64\n",
            " 7   blood_glucose_level  100000 non-null  int64  \n",
            " 8   diabetes             100000 non-null  int64  \n",
            "dtypes: float64(3), int64(6)\n",
            "memory usage: 6.9 MB\n"
          ]
        }
      ],
      "source": [
        "#Loop through all columns in the DataFrame and apply LabelEncoder to Categorical columns\n",
        "label_encoder=LabelEncoder()\n",
        "for column in df.select_dtypes(include=[\"object\"]).columns:\n",
        "  df[column]=label_encoder.fit_transform(df[column])\n",
        "#Display the Dataframe with encoded columns\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0lMoAmPHd5vy"
      },
      "outputs": [],
      "source": [
        "#step 3 split the dataset into training and testing\n",
        "X=df.drop('diabetes',axis=1) #independent variable columns\n",
        "y=df['diabetes'] #Outcome dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx_wAWyDeAjX",
        "outputId": "a0c2d50a-9538-4f34-e884-871488d640b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before SMOTE: Counter({0: 73208, 1: 6792})\n",
            "After SMOTE: Counter({0: 73208, 1: 73208})\n"
          ]
        }
      ],
      "source": [
        "# Assume you have features X and target y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optional: Scale features before SMOTE if needed\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE on training data only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Print class distribution before and after\n",
        "from collections import Counter\n",
        "print(\"Before SMOTE:\", Counter(y_train))\n",
        "print(\"After SMOTE:\", Counter(y_train_res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxBGgKH2eGBl",
        "outputId": "5243e6ef-2f48-4d5f-f0e5-0c42e38f95b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8849\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4buKFNF4eKjf",
        "outputId": "b1df8db6-0816-400b-a37a-830ba68d44f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#step 4:Create an ML Model using Logistic Regression Algorithm\n",
        "model=LogisticRegression()\n",
        "# Now x_train contains only numerical data because preprocessing was done before the split\n",
        "model.fit(X_train_res,y_train_res)\n",
        "y_predict1=model.predict(X_test)\n",
        "y_predict1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAXxCx6hbSk"
      },
      "source": [
        "SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Z1ZDStw1pA5J"
      },
      "outputs": [],
      "source": [
        "model = SGDRegressor()\n",
        "model.fit(X_train_res, y_train_res)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tbnquwnjm8p"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTFJsoVhjpWs",
        "outputId": "308c76c3-3bcf-4e07-8f14-8b32e35ab9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.96145\n",
            "classification rep:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     18292\n",
            "           1       0.79      0.75      0.77      1708\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.88      0.87      0.87     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rfc=RandomForestClassifier()\n",
        "rfc.fit(X_train_res,y_train_res)\n",
        "#step 4: Model Evaluation\n",
        "y_pred=rfc.predict(X_test)\n",
        "y_pred\n",
        "accuracy=accuracy_score(y_test,y_pred)\n",
        "print(\"accuracy:\",accuracy)\n",
        "classification_rep=classification_report(y_test,y_pred)\n",
        "print(\"classification rep:\\n\",classification_rep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUxC5tLTj64F"
      },
      "source": [
        "Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Onfe1bU9j8zx",
        "outputId": "1c1a664d-ad26-4e95-a7b2-3391c1c86a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.086624\n",
            "0:\tlearn: 0.4964121\ttotal: 233ms\tremaining: 3m 52s\n",
            "1:\tlearn: 0.3711544\ttotal: 269ms\tremaining: 2m 14s\n",
            "2:\tlearn: 0.3061078\ttotal: 296ms\tremaining: 1m 38s\n",
            "3:\tlearn: 0.2637309\ttotal: 318ms\tremaining: 1m 19s\n",
            "4:\tlearn: 0.2456165\ttotal: 335ms\tremaining: 1m 6s\n",
            "5:\tlearn: 0.2257245\ttotal: 347ms\tremaining: 57.5s\n",
            "6:\tlearn: 0.2131161\ttotal: 359ms\tremaining: 50.9s\n",
            "7:\tlearn: 0.2033938\ttotal: 370ms\tremaining: 45.9s\n",
            "8:\tlearn: 0.1932980\ttotal: 381ms\tremaining: 42s\n",
            "9:\tlearn: 0.1885658\ttotal: 392ms\tremaining: 38.8s\n",
            "10:\tlearn: 0.1824437\ttotal: 403ms\tremaining: 36.3s\n",
            "11:\tlearn: 0.1758198\ttotal: 414ms\tremaining: 34.1s\n",
            "12:\tlearn: 0.1700524\ttotal: 426ms\tremaining: 32.4s\n",
            "13:\tlearn: 0.1654342\ttotal: 439ms\tremaining: 30.9s\n",
            "14:\tlearn: 0.1609330\ttotal: 451ms\tremaining: 29.6s\n",
            "15:\tlearn: 0.1555688\ttotal: 462ms\tremaining: 28.4s\n",
            "16:\tlearn: 0.1520275\ttotal: 474ms\tremaining: 27.4s\n",
            "17:\tlearn: 0.1462052\ttotal: 486ms\tremaining: 26.5s\n",
            "18:\tlearn: 0.1448990\ttotal: 496ms\tremaining: 25.6s\n",
            "19:\tlearn: 0.1421304\ttotal: 508ms\tremaining: 24.9s\n",
            "20:\tlearn: 0.1386906\ttotal: 520ms\tremaining: 24.2s\n",
            "21:\tlearn: 0.1372132\ttotal: 531ms\tremaining: 23.6s\n",
            "22:\tlearn: 0.1350546\ttotal: 541ms\tremaining: 23s\n",
            "23:\tlearn: 0.1316598\ttotal: 553ms\tremaining: 22.5s\n",
            "24:\tlearn: 0.1265257\ttotal: 565ms\tremaining: 22s\n",
            "25:\tlearn: 0.1254909\ttotal: 576ms\tremaining: 21.6s\n",
            "26:\tlearn: 0.1244756\ttotal: 587ms\tremaining: 21.2s\n",
            "27:\tlearn: 0.1236176\ttotal: 599ms\tremaining: 20.8s\n",
            "28:\tlearn: 0.1212002\ttotal: 609ms\tremaining: 20.4s\n",
            "29:\tlearn: 0.1172085\ttotal: 621ms\tremaining: 20.1s\n",
            "30:\tlearn: 0.1150780\ttotal: 633ms\tremaining: 19.8s\n",
            "31:\tlearn: 0.1131134\ttotal: 645ms\tremaining: 19.5s\n",
            "32:\tlearn: 0.1098951\ttotal: 656ms\tremaining: 19.2s\n",
            "33:\tlearn: 0.1071674\ttotal: 668ms\tremaining: 19s\n",
            "34:\tlearn: 0.1033793\ttotal: 680ms\tremaining: 18.8s\n",
            "35:\tlearn: 0.1017330\ttotal: 691ms\tremaining: 18.5s\n",
            "36:\tlearn: 0.0996658\ttotal: 703ms\tremaining: 18.3s\n",
            "37:\tlearn: 0.0976559\ttotal: 715ms\tremaining: 18.1s\n",
            "38:\tlearn: 0.0954285\ttotal: 727ms\tremaining: 17.9s\n",
            "39:\tlearn: 0.0946940\ttotal: 738ms\tremaining: 17.7s\n",
            "40:\tlearn: 0.0943838\ttotal: 749ms\tremaining: 17.5s\n",
            "41:\tlearn: 0.0925892\ttotal: 761ms\tremaining: 17.4s\n",
            "42:\tlearn: 0.0913521\ttotal: 773ms\tremaining: 17.2s\n",
            "43:\tlearn: 0.0905091\ttotal: 785ms\tremaining: 17.1s\n",
            "44:\tlearn: 0.0900399\ttotal: 798ms\tremaining: 16.9s\n",
            "45:\tlearn: 0.0888362\ttotal: 809ms\tremaining: 16.8s\n",
            "46:\tlearn: 0.0882645\ttotal: 820ms\tremaining: 16.6s\n",
            "47:\tlearn: 0.0875969\ttotal: 832ms\tremaining: 16.5s\n",
            "48:\tlearn: 0.0868957\ttotal: 843ms\tremaining: 16.4s\n",
            "49:\tlearn: 0.0861623\ttotal: 854ms\tremaining: 16.2s\n",
            "50:\tlearn: 0.0859343\ttotal: 866ms\tremaining: 16.1s\n",
            "51:\tlearn: 0.0856726\ttotal: 877ms\tremaining: 16s\n",
            "52:\tlearn: 0.0850778\ttotal: 888ms\tremaining: 15.9s\n",
            "53:\tlearn: 0.0848580\ttotal: 900ms\tremaining: 15.8s\n",
            "54:\tlearn: 0.0845112\ttotal: 912ms\tremaining: 15.7s\n",
            "55:\tlearn: 0.0841214\ttotal: 923ms\tremaining: 15.6s\n",
            "56:\tlearn: 0.0832472\ttotal: 934ms\tremaining: 15.5s\n",
            "57:\tlearn: 0.0828192\ttotal: 946ms\tremaining: 15.4s\n",
            "58:\tlearn: 0.0826715\ttotal: 958ms\tremaining: 15.3s\n",
            "59:\tlearn: 0.0825581\ttotal: 968ms\tremaining: 15.2s\n",
            "60:\tlearn: 0.0823571\ttotal: 980ms\tremaining: 15.1s\n",
            "61:\tlearn: 0.0821106\ttotal: 992ms\tremaining: 15s\n",
            "62:\tlearn: 0.0818056\ttotal: 1s\tremaining: 14.9s\n",
            "63:\tlearn: 0.0809977\ttotal: 1.01s\tremaining: 14.8s\n",
            "64:\tlearn: 0.0806592\ttotal: 1.02s\tremaining: 14.8s\n",
            "65:\tlearn: 0.0804812\ttotal: 1.04s\tremaining: 14.7s\n",
            "66:\tlearn: 0.0800026\ttotal: 1.05s\tremaining: 14.6s\n",
            "67:\tlearn: 0.0797451\ttotal: 1.06s\tremaining: 14.5s\n",
            "68:\tlearn: 0.0796257\ttotal: 1.07s\tremaining: 14.4s\n",
            "69:\tlearn: 0.0791269\ttotal: 1.08s\tremaining: 14.4s\n",
            "70:\tlearn: 0.0778894\ttotal: 1.09s\tremaining: 14.3s\n",
            "71:\tlearn: 0.0776988\ttotal: 1.1s\tremaining: 14.2s\n",
            "72:\tlearn: 0.0762845\ttotal: 1.11s\tremaining: 14.2s\n",
            "73:\tlearn: 0.0761776\ttotal: 1.13s\tremaining: 14.1s\n",
            "74:\tlearn: 0.0761118\ttotal: 1.14s\tremaining: 14s\n",
            "75:\tlearn: 0.0755793\ttotal: 1.15s\tremaining: 14s\n",
            "76:\tlearn: 0.0754024\ttotal: 1.16s\tremaining: 13.9s\n",
            "77:\tlearn: 0.0748046\ttotal: 1.17s\tremaining: 13.9s\n",
            "78:\tlearn: 0.0746832\ttotal: 1.19s\tremaining: 13.8s\n",
            "79:\tlearn: 0.0745566\ttotal: 1.2s\tremaining: 13.8s\n",
            "80:\tlearn: 0.0744628\ttotal: 1.21s\tremaining: 13.7s\n",
            "81:\tlearn: 0.0741051\ttotal: 1.22s\tremaining: 13.7s\n",
            "82:\tlearn: 0.0739117\ttotal: 1.23s\tremaining: 13.6s\n",
            "83:\tlearn: 0.0737605\ttotal: 1.24s\tremaining: 13.6s\n",
            "84:\tlearn: 0.0736523\ttotal: 1.25s\tremaining: 13.5s\n",
            "85:\tlearn: 0.0731945\ttotal: 1.26s\tremaining: 13.5s\n",
            "86:\tlearn: 0.0729444\ttotal: 1.28s\tremaining: 13.4s\n",
            "87:\tlearn: 0.0726960\ttotal: 1.29s\tremaining: 13.4s\n",
            "88:\tlearn: 0.0725814\ttotal: 1.3s\tremaining: 13.3s\n",
            "89:\tlearn: 0.0723264\ttotal: 1.31s\tremaining: 13.3s\n",
            "90:\tlearn: 0.0720209\ttotal: 1.32s\tremaining: 13.2s\n",
            "91:\tlearn: 0.0719721\ttotal: 1.33s\tremaining: 13.2s\n",
            "92:\tlearn: 0.0717839\ttotal: 1.34s\tremaining: 13.1s\n",
            "93:\tlearn: 0.0715847\ttotal: 1.35s\tremaining: 13.1s\n",
            "94:\tlearn: 0.0714942\ttotal: 1.37s\tremaining: 13s\n",
            "95:\tlearn: 0.0713580\ttotal: 1.38s\tremaining: 13s\n",
            "96:\tlearn: 0.0708954\ttotal: 1.39s\tremaining: 12.9s\n",
            "97:\tlearn: 0.0707394\ttotal: 1.4s\tremaining: 12.9s\n",
            "98:\tlearn: 0.0705733\ttotal: 1.41s\tremaining: 12.8s\n",
            "99:\tlearn: 0.0704028\ttotal: 1.42s\tremaining: 12.8s\n",
            "100:\tlearn: 0.0700544\ttotal: 1.43s\tremaining: 12.8s\n",
            "101:\tlearn: 0.0697602\ttotal: 1.45s\tremaining: 12.7s\n",
            "102:\tlearn: 0.0694930\ttotal: 1.46s\tremaining: 12.7s\n",
            "103:\tlearn: 0.0690151\ttotal: 1.47s\tremaining: 12.6s\n",
            "104:\tlearn: 0.0689763\ttotal: 1.48s\tremaining: 12.6s\n",
            "105:\tlearn: 0.0683668\ttotal: 1.49s\tremaining: 12.6s\n",
            "106:\tlearn: 0.0683169\ttotal: 1.5s\tremaining: 12.5s\n",
            "107:\tlearn: 0.0680165\ttotal: 1.51s\tremaining: 12.5s\n",
            "108:\tlearn: 0.0677853\ttotal: 1.52s\tremaining: 12.5s\n",
            "109:\tlearn: 0.0676330\ttotal: 1.53s\tremaining: 12.4s\n",
            "110:\tlearn: 0.0674850\ttotal: 1.55s\tremaining: 12.4s\n",
            "111:\tlearn: 0.0672926\ttotal: 1.56s\tremaining: 12.3s\n",
            "112:\tlearn: 0.0670562\ttotal: 1.57s\tremaining: 12.3s\n",
            "113:\tlearn: 0.0670129\ttotal: 1.58s\tremaining: 12.3s\n",
            "114:\tlearn: 0.0667448\ttotal: 1.59s\tremaining: 12.2s\n",
            "115:\tlearn: 0.0663838\ttotal: 1.6s\tremaining: 12.2s\n",
            "116:\tlearn: 0.0662378\ttotal: 1.61s\tremaining: 12.2s\n",
            "117:\tlearn: 0.0660840\ttotal: 1.62s\tremaining: 12.1s\n",
            "118:\tlearn: 0.0660108\ttotal: 1.64s\tremaining: 12.1s\n",
            "119:\tlearn: 0.0655806\ttotal: 1.65s\tremaining: 12.1s\n",
            "120:\tlearn: 0.0654166\ttotal: 1.66s\tremaining: 12.1s\n",
            "121:\tlearn: 0.0650922\ttotal: 1.67s\tremaining: 12s\n",
            "122:\tlearn: 0.0650050\ttotal: 1.68s\tremaining: 12s\n",
            "123:\tlearn: 0.0649356\ttotal: 1.69s\tremaining: 12s\n",
            "124:\tlearn: 0.0647539\ttotal: 1.71s\tremaining: 11.9s\n",
            "125:\tlearn: 0.0645394\ttotal: 1.72s\tremaining: 11.9s\n",
            "126:\tlearn: 0.0644257\ttotal: 1.73s\tremaining: 11.9s\n",
            "127:\tlearn: 0.0643601\ttotal: 1.74s\tremaining: 11.9s\n",
            "128:\tlearn: 0.0641601\ttotal: 1.75s\tremaining: 11.8s\n",
            "129:\tlearn: 0.0640253\ttotal: 1.76s\tremaining: 11.8s\n",
            "130:\tlearn: 0.0638339\ttotal: 1.78s\tremaining: 11.8s\n",
            "131:\tlearn: 0.0637891\ttotal: 1.79s\tremaining: 11.8s\n",
            "132:\tlearn: 0.0636704\ttotal: 1.8s\tremaining: 11.7s\n",
            "133:\tlearn: 0.0635624\ttotal: 1.81s\tremaining: 11.7s\n",
            "134:\tlearn: 0.0632635\ttotal: 1.82s\tremaining: 11.7s\n",
            "135:\tlearn: 0.0631747\ttotal: 1.83s\tremaining: 11.6s\n",
            "136:\tlearn: 0.0630802\ttotal: 1.84s\tremaining: 11.6s\n",
            "137:\tlearn: 0.0628894\ttotal: 1.85s\tremaining: 11.6s\n",
            "138:\tlearn: 0.0628532\ttotal: 1.87s\tremaining: 11.6s\n",
            "139:\tlearn: 0.0628166\ttotal: 1.88s\tremaining: 11.5s\n",
            "140:\tlearn: 0.0627688\ttotal: 1.89s\tremaining: 11.5s\n",
            "141:\tlearn: 0.0626106\ttotal: 1.9s\tremaining: 11.5s\n",
            "142:\tlearn: 0.0625153\ttotal: 1.91s\tremaining: 11.5s\n",
            "143:\tlearn: 0.0623480\ttotal: 1.93s\tremaining: 11.4s\n",
            "144:\tlearn: 0.0620659\ttotal: 1.94s\tremaining: 11.4s\n",
            "145:\tlearn: 0.0619199\ttotal: 1.95s\tremaining: 11.4s\n",
            "146:\tlearn: 0.0618476\ttotal: 1.96s\tremaining: 11.4s\n",
            "147:\tlearn: 0.0617207\ttotal: 1.97s\tremaining: 11.4s\n",
            "148:\tlearn: 0.0615796\ttotal: 1.98s\tremaining: 11.3s\n",
            "149:\tlearn: 0.0613869\ttotal: 2s\tremaining: 11.3s\n",
            "150:\tlearn: 0.0613179\ttotal: 2.01s\tremaining: 11.3s\n",
            "151:\tlearn: 0.0611835\ttotal: 2.02s\tremaining: 11.3s\n",
            "152:\tlearn: 0.0611151\ttotal: 2.03s\tremaining: 11.2s\n",
            "153:\tlearn: 0.0610178\ttotal: 2.04s\tremaining: 11.2s\n",
            "154:\tlearn: 0.0608312\ttotal: 2.05s\tremaining: 11.2s\n",
            "155:\tlearn: 0.0607429\ttotal: 2.06s\tremaining: 11.2s\n",
            "156:\tlearn: 0.0606728\ttotal: 2.07s\tremaining: 11.1s\n",
            "157:\tlearn: 0.0605725\ttotal: 2.08s\tremaining: 11.1s\n",
            "158:\tlearn: 0.0605295\ttotal: 2.1s\tremaining: 11.1s\n",
            "159:\tlearn: 0.0604233\ttotal: 2.11s\tremaining: 11.1s\n",
            "160:\tlearn: 0.0603810\ttotal: 2.12s\tremaining: 11s\n",
            "161:\tlearn: 0.0602303\ttotal: 2.13s\tremaining: 11s\n",
            "162:\tlearn: 0.0600936\ttotal: 2.14s\tremaining: 11s\n",
            "163:\tlearn: 0.0600182\ttotal: 2.15s\tremaining: 11s\n",
            "164:\tlearn: 0.0599264\ttotal: 2.16s\tremaining: 10.9s\n",
            "165:\tlearn: 0.0597926\ttotal: 2.17s\tremaining: 10.9s\n",
            "166:\tlearn: 0.0597126\ttotal: 2.19s\tremaining: 10.9s\n",
            "167:\tlearn: 0.0596616\ttotal: 2.2s\tremaining: 10.9s\n",
            "168:\tlearn: 0.0594582\ttotal: 2.21s\tremaining: 10.9s\n",
            "169:\tlearn: 0.0593425\ttotal: 2.22s\tremaining: 10.8s\n",
            "170:\tlearn: 0.0591487\ttotal: 2.23s\tremaining: 10.8s\n",
            "171:\tlearn: 0.0590226\ttotal: 2.24s\tremaining: 10.8s\n",
            "172:\tlearn: 0.0588944\ttotal: 2.25s\tremaining: 10.8s\n",
            "173:\tlearn: 0.0588109\ttotal: 2.26s\tremaining: 10.7s\n",
            "174:\tlearn: 0.0587230\ttotal: 2.27s\tremaining: 10.7s\n",
            "175:\tlearn: 0.0586766\ttotal: 2.29s\tremaining: 10.7s\n",
            "176:\tlearn: 0.0586112\ttotal: 2.3s\tremaining: 10.7s\n",
            "177:\tlearn: 0.0585373\ttotal: 2.31s\tremaining: 10.7s\n",
            "178:\tlearn: 0.0583822\ttotal: 2.32s\tremaining: 10.7s\n",
            "179:\tlearn: 0.0582830\ttotal: 2.33s\tremaining: 10.6s\n",
            "180:\tlearn: 0.0581567\ttotal: 2.35s\tremaining: 10.6s\n",
            "181:\tlearn: 0.0580135\ttotal: 2.36s\tremaining: 10.6s\n",
            "182:\tlearn: 0.0579563\ttotal: 2.37s\tremaining: 10.6s\n",
            "183:\tlearn: 0.0578809\ttotal: 2.38s\tremaining: 10.6s\n",
            "184:\tlearn: 0.0577970\ttotal: 2.39s\tremaining: 10.5s\n",
            "185:\tlearn: 0.0577100\ttotal: 2.4s\tremaining: 10.5s\n",
            "186:\tlearn: 0.0576625\ttotal: 2.42s\tremaining: 10.5s\n",
            "187:\tlearn: 0.0576458\ttotal: 2.43s\tremaining: 10.5s\n",
            "188:\tlearn: 0.0575267\ttotal: 2.44s\tremaining: 10.5s\n",
            "189:\tlearn: 0.0574826\ttotal: 2.45s\tremaining: 10.4s\n",
            "190:\tlearn: 0.0574085\ttotal: 2.46s\tremaining: 10.4s\n",
            "191:\tlearn: 0.0573189\ttotal: 2.47s\tremaining: 10.4s\n",
            "192:\tlearn: 0.0571928\ttotal: 2.49s\tremaining: 10.4s\n",
            "193:\tlearn: 0.0571288\ttotal: 2.5s\tremaining: 10.4s\n",
            "194:\tlearn: 0.0570826\ttotal: 2.51s\tremaining: 10.4s\n",
            "195:\tlearn: 0.0568948\ttotal: 2.52s\tremaining: 10.3s\n",
            "196:\tlearn: 0.0568729\ttotal: 2.53s\tremaining: 10.3s\n",
            "197:\tlearn: 0.0568212\ttotal: 2.54s\tremaining: 10.3s\n",
            "198:\tlearn: 0.0567771\ttotal: 2.56s\tremaining: 10.3s\n",
            "199:\tlearn: 0.0567275\ttotal: 2.57s\tremaining: 10.3s\n",
            "200:\tlearn: 0.0566901\ttotal: 2.58s\tremaining: 10.2s\n",
            "201:\tlearn: 0.0565661\ttotal: 2.59s\tremaining: 10.2s\n",
            "202:\tlearn: 0.0565162\ttotal: 2.6s\tremaining: 10.2s\n",
            "203:\tlearn: 0.0564477\ttotal: 2.61s\tremaining: 10.2s\n",
            "204:\tlearn: 0.0563553\ttotal: 2.62s\tremaining: 10.2s\n",
            "205:\tlearn: 0.0563023\ttotal: 2.64s\tremaining: 10.2s\n",
            "206:\tlearn: 0.0561673\ttotal: 2.65s\tremaining: 10.1s\n",
            "207:\tlearn: 0.0560644\ttotal: 2.66s\tremaining: 10.1s\n",
            "208:\tlearn: 0.0559484\ttotal: 2.67s\tremaining: 10.1s\n",
            "209:\tlearn: 0.0558297\ttotal: 2.68s\tremaining: 10.1s\n",
            "210:\tlearn: 0.0558004\ttotal: 2.7s\tremaining: 10.1s\n",
            "211:\tlearn: 0.0557465\ttotal: 2.71s\tremaining: 10.1s\n",
            "212:\tlearn: 0.0556984\ttotal: 2.72s\tremaining: 10s\n",
            "213:\tlearn: 0.0556316\ttotal: 2.73s\tremaining: 10s\n",
            "214:\tlearn: 0.0555419\ttotal: 2.74s\tremaining: 10s\n",
            "215:\tlearn: 0.0555057\ttotal: 2.75s\tremaining: 9.99s\n",
            "216:\tlearn: 0.0554502\ttotal: 2.76s\tremaining: 9.97s\n",
            "217:\tlearn: 0.0553090\ttotal: 2.78s\tremaining: 9.96s\n",
            "218:\tlearn: 0.0552199\ttotal: 2.79s\tremaining: 9.94s\n",
            "219:\tlearn: 0.0551406\ttotal: 2.8s\tremaining: 9.92s\n",
            "220:\tlearn: 0.0550956\ttotal: 2.81s\tremaining: 9.91s\n",
            "221:\tlearn: 0.0550433\ttotal: 2.82s\tremaining: 9.89s\n",
            "222:\tlearn: 0.0549637\ttotal: 2.83s\tremaining: 9.87s\n",
            "223:\tlearn: 0.0549345\ttotal: 2.84s\tremaining: 9.85s\n",
            "224:\tlearn: 0.0548566\ttotal: 2.85s\tremaining: 9.83s\n",
            "225:\tlearn: 0.0548002\ttotal: 2.87s\tremaining: 9.82s\n",
            "226:\tlearn: 0.0547497\ttotal: 2.88s\tremaining: 9.81s\n",
            "227:\tlearn: 0.0547351\ttotal: 2.89s\tremaining: 9.8s\n",
            "228:\tlearn: 0.0546892\ttotal: 2.9s\tremaining: 9.78s\n",
            "229:\tlearn: 0.0546457\ttotal: 2.92s\tremaining: 9.76s\n",
            "230:\tlearn: 0.0546247\ttotal: 2.93s\tremaining: 9.75s\n",
            "231:\tlearn: 0.0545587\ttotal: 2.94s\tremaining: 9.73s\n",
            "232:\tlearn: 0.0545174\ttotal: 2.95s\tremaining: 9.72s\n",
            "233:\tlearn: 0.0544898\ttotal: 2.96s\tremaining: 9.7s\n",
            "234:\tlearn: 0.0544395\ttotal: 2.98s\tremaining: 9.69s\n",
            "235:\tlearn: 0.0543100\ttotal: 2.99s\tremaining: 9.67s\n",
            "236:\tlearn: 0.0542736\ttotal: 3s\tremaining: 9.65s\n",
            "237:\tlearn: 0.0542379\ttotal: 3.01s\tremaining: 9.64s\n",
            "238:\tlearn: 0.0542272\ttotal: 3.02s\tremaining: 9.62s\n",
            "239:\tlearn: 0.0542039\ttotal: 3.03s\tremaining: 9.6s\n",
            "240:\tlearn: 0.0540811\ttotal: 3.04s\tremaining: 9.58s\n",
            "241:\tlearn: 0.0539776\ttotal: 3.06s\tremaining: 9.57s\n",
            "242:\tlearn: 0.0539608\ttotal: 3.07s\tremaining: 9.56s\n",
            "243:\tlearn: 0.0539092\ttotal: 3.08s\tremaining: 9.54s\n",
            "244:\tlearn: 0.0538350\ttotal: 3.09s\tremaining: 9.52s\n",
            "245:\tlearn: 0.0538026\ttotal: 3.1s\tremaining: 9.51s\n",
            "246:\tlearn: 0.0537259\ttotal: 3.11s\tremaining: 9.49s\n",
            "247:\tlearn: 0.0536636\ttotal: 3.13s\tremaining: 9.48s\n",
            "248:\tlearn: 0.0536079\ttotal: 3.14s\tremaining: 9.46s\n",
            "249:\tlearn: 0.0535473\ttotal: 3.15s\tremaining: 9.44s\n",
            "250:\tlearn: 0.0535110\ttotal: 3.16s\tremaining: 9.43s\n",
            "251:\tlearn: 0.0534958\ttotal: 3.17s\tremaining: 9.41s\n",
            "252:\tlearn: 0.0534662\ttotal: 3.18s\tremaining: 9.4s\n",
            "253:\tlearn: 0.0533645\ttotal: 3.19s\tremaining: 9.38s\n",
            "254:\tlearn: 0.0533429\ttotal: 3.21s\tremaining: 9.37s\n",
            "255:\tlearn: 0.0532819\ttotal: 3.22s\tremaining: 9.36s\n",
            "256:\tlearn: 0.0532174\ttotal: 3.23s\tremaining: 9.34s\n",
            "257:\tlearn: 0.0531696\ttotal: 3.24s\tremaining: 9.32s\n",
            "258:\tlearn: 0.0531079\ttotal: 3.25s\tremaining: 9.31s\n",
            "259:\tlearn: 0.0530028\ttotal: 3.27s\tremaining: 9.29s\n",
            "260:\tlearn: 0.0529391\ttotal: 3.28s\tremaining: 9.28s\n",
            "261:\tlearn: 0.0528758\ttotal: 3.29s\tremaining: 9.26s\n",
            "262:\tlearn: 0.0528252\ttotal: 3.3s\tremaining: 9.25s\n",
            "263:\tlearn: 0.0527974\ttotal: 3.31s\tremaining: 9.23s\n",
            "264:\tlearn: 0.0527739\ttotal: 3.32s\tremaining: 9.22s\n",
            "265:\tlearn: 0.0527488\ttotal: 3.33s\tremaining: 9.2s\n",
            "266:\tlearn: 0.0526884\ttotal: 3.35s\tremaining: 9.18s\n",
            "267:\tlearn: 0.0526520\ttotal: 3.36s\tremaining: 9.17s\n",
            "268:\tlearn: 0.0526103\ttotal: 3.37s\tremaining: 9.15s\n",
            "269:\tlearn: 0.0525606\ttotal: 3.38s\tremaining: 9.13s\n",
            "270:\tlearn: 0.0525341\ttotal: 3.39s\tremaining: 9.12s\n",
            "271:\tlearn: 0.0525261\ttotal: 3.4s\tremaining: 9.1s\n",
            "272:\tlearn: 0.0524550\ttotal: 3.41s\tremaining: 9.09s\n",
            "273:\tlearn: 0.0523656\ttotal: 3.42s\tremaining: 9.07s\n",
            "274:\tlearn: 0.0523029\ttotal: 3.43s\tremaining: 9.05s\n",
            "275:\tlearn: 0.0522712\ttotal: 3.44s\tremaining: 9.04s\n",
            "276:\tlearn: 0.0522422\ttotal: 3.46s\tremaining: 9.02s\n",
            "277:\tlearn: 0.0521956\ttotal: 3.47s\tremaining: 9.01s\n",
            "278:\tlearn: 0.0521344\ttotal: 3.48s\tremaining: 8.99s\n",
            "279:\tlearn: 0.0521162\ttotal: 3.49s\tremaining: 8.98s\n",
            "280:\tlearn: 0.0520706\ttotal: 3.5s\tremaining: 8.96s\n",
            "281:\tlearn: 0.0520059\ttotal: 3.52s\tremaining: 8.95s\n",
            "282:\tlearn: 0.0519706\ttotal: 3.53s\tremaining: 8.93s\n",
            "283:\tlearn: 0.0519473\ttotal: 3.54s\tremaining: 8.92s\n",
            "284:\tlearn: 0.0519027\ttotal: 3.55s\tremaining: 8.9s\n",
            "285:\tlearn: 0.0518784\ttotal: 3.56s\tremaining: 8.89s\n",
            "286:\tlearn: 0.0518458\ttotal: 3.57s\tremaining: 8.87s\n",
            "287:\tlearn: 0.0518188\ttotal: 3.58s\tremaining: 8.86s\n",
            "288:\tlearn: 0.0518043\ttotal: 3.59s\tremaining: 8.84s\n",
            "289:\tlearn: 0.0517688\ttotal: 3.6s\tremaining: 8.83s\n",
            "290:\tlearn: 0.0517238\ttotal: 3.62s\tremaining: 8.81s\n",
            "291:\tlearn: 0.0517079\ttotal: 3.63s\tremaining: 8.8s\n",
            "292:\tlearn: 0.0516605\ttotal: 3.64s\tremaining: 8.78s\n",
            "293:\tlearn: 0.0516239\ttotal: 3.65s\tremaining: 8.76s\n",
            "294:\tlearn: 0.0515749\ttotal: 3.66s\tremaining: 8.75s\n",
            "295:\tlearn: 0.0515361\ttotal: 3.67s\tremaining: 8.73s\n",
            "296:\tlearn: 0.0514875\ttotal: 3.68s\tremaining: 8.72s\n",
            "297:\tlearn: 0.0514244\ttotal: 3.69s\tremaining: 8.71s\n",
            "298:\tlearn: 0.0513673\ttotal: 3.71s\tremaining: 8.69s\n",
            "299:\tlearn: 0.0513156\ttotal: 3.72s\tremaining: 8.67s\n",
            "300:\tlearn: 0.0513049\ttotal: 3.73s\tremaining: 8.66s\n",
            "301:\tlearn: 0.0512609\ttotal: 3.74s\tremaining: 8.64s\n",
            "302:\tlearn: 0.0511919\ttotal: 3.75s\tremaining: 8.63s\n",
            "303:\tlearn: 0.0511580\ttotal: 3.76s\tremaining: 8.62s\n",
            "304:\tlearn: 0.0511424\ttotal: 3.77s\tremaining: 8.6s\n",
            "305:\tlearn: 0.0511249\ttotal: 3.79s\tremaining: 8.59s\n",
            "306:\tlearn: 0.0510542\ttotal: 3.8s\tremaining: 8.57s\n",
            "307:\tlearn: 0.0510294\ttotal: 3.81s\tremaining: 8.56s\n",
            "308:\tlearn: 0.0510175\ttotal: 3.82s\tremaining: 8.54s\n",
            "309:\tlearn: 0.0509944\ttotal: 3.83s\tremaining: 8.53s\n",
            "310:\tlearn: 0.0509611\ttotal: 3.84s\tremaining: 8.52s\n",
            "311:\tlearn: 0.0509160\ttotal: 3.85s\tremaining: 8.5s\n",
            "312:\tlearn: 0.0508673\ttotal: 3.87s\tremaining: 8.49s\n",
            "313:\tlearn: 0.0508365\ttotal: 3.88s\tremaining: 8.47s\n",
            "314:\tlearn: 0.0508115\ttotal: 3.89s\tremaining: 8.46s\n",
            "315:\tlearn: 0.0507840\ttotal: 3.9s\tremaining: 8.44s\n",
            "316:\tlearn: 0.0507730\ttotal: 3.91s\tremaining: 8.43s\n",
            "317:\tlearn: 0.0507515\ttotal: 3.92s\tremaining: 8.41s\n",
            "318:\tlearn: 0.0506945\ttotal: 3.94s\tremaining: 8.4s\n",
            "319:\tlearn: 0.0506366\ttotal: 3.95s\tremaining: 8.39s\n",
            "320:\tlearn: 0.0506105\ttotal: 3.96s\tremaining: 8.37s\n",
            "321:\tlearn: 0.0505762\ttotal: 3.97s\tremaining: 8.36s\n",
            "322:\tlearn: 0.0505554\ttotal: 3.98s\tremaining: 8.35s\n",
            "323:\tlearn: 0.0504802\ttotal: 3.99s\tremaining: 8.33s\n",
            "324:\tlearn: 0.0504444\ttotal: 4s\tremaining: 8.32s\n",
            "325:\tlearn: 0.0504219\ttotal: 4.01s\tremaining: 8.3s\n",
            "326:\tlearn: 0.0503949\ttotal: 4.03s\tremaining: 8.29s\n",
            "327:\tlearn: 0.0503652\ttotal: 4.04s\tremaining: 8.28s\n",
            "328:\tlearn: 0.0503348\ttotal: 4.05s\tremaining: 8.26s\n",
            "329:\tlearn: 0.0502941\ttotal: 4.06s\tremaining: 8.25s\n",
            "330:\tlearn: 0.0502563\ttotal: 4.07s\tremaining: 8.23s\n",
            "331:\tlearn: 0.0502250\ttotal: 4.08s\tremaining: 8.22s\n",
            "332:\tlearn: 0.0501709\ttotal: 4.1s\tremaining: 8.21s\n",
            "333:\tlearn: 0.0501491\ttotal: 4.11s\tremaining: 8.19s\n",
            "334:\tlearn: 0.0500820\ttotal: 4.12s\tremaining: 8.18s\n",
            "335:\tlearn: 0.0500588\ttotal: 4.13s\tremaining: 8.17s\n",
            "336:\tlearn: 0.0500351\ttotal: 4.14s\tremaining: 8.15s\n",
            "337:\tlearn: 0.0500020\ttotal: 4.16s\tremaining: 8.14s\n",
            "338:\tlearn: 0.0499694\ttotal: 4.17s\tremaining: 8.12s\n",
            "339:\tlearn: 0.0499350\ttotal: 4.18s\tremaining: 8.11s\n",
            "340:\tlearn: 0.0498998\ttotal: 4.19s\tremaining: 8.1s\n",
            "341:\tlearn: 0.0498415\ttotal: 4.2s\tremaining: 8.08s\n",
            "342:\tlearn: 0.0498098\ttotal: 4.21s\tremaining: 8.07s\n",
            "343:\tlearn: 0.0497423\ttotal: 4.22s\tremaining: 8.06s\n",
            "344:\tlearn: 0.0497117\ttotal: 4.24s\tremaining: 8.04s\n",
            "345:\tlearn: 0.0496963\ttotal: 4.25s\tremaining: 8.03s\n",
            "346:\tlearn: 0.0496728\ttotal: 4.26s\tremaining: 8.02s\n",
            "347:\tlearn: 0.0496375\ttotal: 4.27s\tremaining: 8s\n",
            "348:\tlearn: 0.0495950\ttotal: 4.28s\tremaining: 7.99s\n",
            "349:\tlearn: 0.0495500\ttotal: 4.3s\tremaining: 7.98s\n",
            "350:\tlearn: 0.0495281\ttotal: 4.31s\tremaining: 7.97s\n",
            "351:\tlearn: 0.0494834\ttotal: 4.32s\tremaining: 7.95s\n",
            "352:\tlearn: 0.0494616\ttotal: 4.33s\tremaining: 7.94s\n",
            "353:\tlearn: 0.0494396\ttotal: 4.34s\tremaining: 7.92s\n",
            "354:\tlearn: 0.0494227\ttotal: 4.35s\tremaining: 7.91s\n",
            "355:\tlearn: 0.0494083\ttotal: 4.36s\tremaining: 7.9s\n",
            "356:\tlearn: 0.0493737\ttotal: 4.38s\tremaining: 7.88s\n",
            "357:\tlearn: 0.0493296\ttotal: 4.39s\tremaining: 7.87s\n",
            "358:\tlearn: 0.0492966\ttotal: 4.4s\tremaining: 7.86s\n",
            "359:\tlearn: 0.0492572\ttotal: 4.41s\tremaining: 7.84s\n",
            "360:\tlearn: 0.0492347\ttotal: 4.42s\tremaining: 7.83s\n",
            "361:\tlearn: 0.0491911\ttotal: 4.43s\tremaining: 7.82s\n",
            "362:\tlearn: 0.0491689\ttotal: 4.45s\tremaining: 7.8s\n",
            "363:\tlearn: 0.0491339\ttotal: 4.46s\tremaining: 7.79s\n",
            "364:\tlearn: 0.0491118\ttotal: 4.47s\tremaining: 7.78s\n",
            "365:\tlearn: 0.0490719\ttotal: 4.48s\tremaining: 7.76s\n",
            "366:\tlearn: 0.0490556\ttotal: 4.49s\tremaining: 7.75s\n",
            "367:\tlearn: 0.0490223\ttotal: 4.5s\tremaining: 7.74s\n",
            "368:\tlearn: 0.0489608\ttotal: 4.52s\tremaining: 7.72s\n",
            "369:\tlearn: 0.0489158\ttotal: 4.53s\tremaining: 7.71s\n",
            "370:\tlearn: 0.0488810\ttotal: 4.54s\tremaining: 7.7s\n",
            "371:\tlearn: 0.0488592\ttotal: 4.55s\tremaining: 7.68s\n",
            "372:\tlearn: 0.0488410\ttotal: 4.56s\tremaining: 7.67s\n",
            "373:\tlearn: 0.0488176\ttotal: 4.57s\tremaining: 7.65s\n",
            "374:\tlearn: 0.0488083\ttotal: 4.58s\tremaining: 7.64s\n",
            "375:\tlearn: 0.0487597\ttotal: 4.59s\tremaining: 7.63s\n",
            "376:\tlearn: 0.0487264\ttotal: 4.61s\tremaining: 7.61s\n",
            "377:\tlearn: 0.0487082\ttotal: 4.62s\tremaining: 7.6s\n",
            "378:\tlearn: 0.0486657\ttotal: 4.63s\tremaining: 7.58s\n",
            "379:\tlearn: 0.0486187\ttotal: 4.64s\tremaining: 7.57s\n",
            "380:\tlearn: 0.0485930\ttotal: 4.65s\tremaining: 7.56s\n",
            "381:\tlearn: 0.0485695\ttotal: 4.66s\tremaining: 7.54s\n",
            "382:\tlearn: 0.0485292\ttotal: 4.67s\tremaining: 7.53s\n",
            "383:\tlearn: 0.0484848\ttotal: 4.69s\tremaining: 7.52s\n",
            "384:\tlearn: 0.0484620\ttotal: 4.7s\tremaining: 7.5s\n",
            "385:\tlearn: 0.0484357\ttotal: 4.71s\tremaining: 7.49s\n",
            "386:\tlearn: 0.0484156\ttotal: 4.72s\tremaining: 7.48s\n",
            "387:\tlearn: 0.0483909\ttotal: 4.73s\tremaining: 7.47s\n",
            "388:\tlearn: 0.0483757\ttotal: 4.75s\tremaining: 7.45s\n",
            "389:\tlearn: 0.0483456\ttotal: 4.76s\tremaining: 7.44s\n",
            "390:\tlearn: 0.0483220\ttotal: 4.77s\tremaining: 7.43s\n",
            "391:\tlearn: 0.0483047\ttotal: 4.78s\tremaining: 7.42s\n",
            "392:\tlearn: 0.0482810\ttotal: 4.79s\tremaining: 7.4s\n",
            "393:\tlearn: 0.0482606\ttotal: 4.8s\tremaining: 7.39s\n",
            "394:\tlearn: 0.0482149\ttotal: 4.81s\tremaining: 7.37s\n",
            "395:\tlearn: 0.0482073\ttotal: 4.83s\tremaining: 7.36s\n",
            "396:\tlearn: 0.0481717\ttotal: 4.84s\tremaining: 7.35s\n",
            "397:\tlearn: 0.0481497\ttotal: 4.85s\tremaining: 7.33s\n",
            "398:\tlearn: 0.0481360\ttotal: 4.86s\tremaining: 7.32s\n",
            "399:\tlearn: 0.0481211\ttotal: 4.87s\tremaining: 7.3s\n",
            "400:\tlearn: 0.0481038\ttotal: 4.88s\tremaining: 7.29s\n",
            "401:\tlearn: 0.0480852\ttotal: 4.89s\tremaining: 7.28s\n",
            "402:\tlearn: 0.0480596\ttotal: 4.91s\tremaining: 7.27s\n",
            "403:\tlearn: 0.0480468\ttotal: 4.92s\tremaining: 7.25s\n",
            "404:\tlearn: 0.0480154\ttotal: 4.93s\tremaining: 7.24s\n",
            "405:\tlearn: 0.0479882\ttotal: 4.94s\tremaining: 7.23s\n",
            "406:\tlearn: 0.0479599\ttotal: 4.95s\tremaining: 7.21s\n",
            "407:\tlearn: 0.0479349\ttotal: 4.96s\tremaining: 7.2s\n",
            "408:\tlearn: 0.0478537\ttotal: 4.97s\tremaining: 7.19s\n",
            "409:\tlearn: 0.0478443\ttotal: 4.98s\tremaining: 7.17s\n",
            "410:\tlearn: 0.0478022\ttotal: 5s\tremaining: 7.16s\n",
            "411:\tlearn: 0.0477819\ttotal: 5.01s\tremaining: 7.15s\n",
            "412:\tlearn: 0.0477528\ttotal: 5.02s\tremaining: 7.13s\n",
            "413:\tlearn: 0.0477238\ttotal: 5.03s\tremaining: 7.12s\n",
            "414:\tlearn: 0.0476929\ttotal: 5.04s\tremaining: 7.11s\n",
            "415:\tlearn: 0.0476518\ttotal: 5.05s\tremaining: 7.09s\n",
            "416:\tlearn: 0.0476350\ttotal: 5.06s\tremaining: 7.08s\n",
            "417:\tlearn: 0.0476038\ttotal: 5.08s\tremaining: 7.07s\n",
            "418:\tlearn: 0.0475837\ttotal: 5.09s\tremaining: 7.05s\n",
            "419:\tlearn: 0.0475208\ttotal: 5.1s\tremaining: 7.04s\n",
            "420:\tlearn: 0.0474863\ttotal: 5.11s\tremaining: 7.03s\n",
            "421:\tlearn: 0.0474728\ttotal: 5.12s\tremaining: 7.02s\n",
            "422:\tlearn: 0.0474291\ttotal: 5.13s\tremaining: 7s\n",
            "423:\tlearn: 0.0474035\ttotal: 5.14s\tremaining: 6.99s\n",
            "424:\tlearn: 0.0473843\ttotal: 5.16s\tremaining: 6.98s\n",
            "425:\tlearn: 0.0473583\ttotal: 5.17s\tremaining: 6.96s\n",
            "426:\tlearn: 0.0473434\ttotal: 5.18s\tremaining: 6.95s\n",
            "427:\tlearn: 0.0473284\ttotal: 5.19s\tremaining: 6.94s\n",
            "428:\tlearn: 0.0473120\ttotal: 5.2s\tremaining: 6.92s\n",
            "429:\tlearn: 0.0472772\ttotal: 5.21s\tremaining: 6.91s\n",
            "430:\tlearn: 0.0472681\ttotal: 5.22s\tremaining: 6.9s\n",
            "431:\tlearn: 0.0472355\ttotal: 5.24s\tremaining: 6.88s\n",
            "432:\tlearn: 0.0472142\ttotal: 5.25s\tremaining: 6.87s\n",
            "433:\tlearn: 0.0471911\ttotal: 5.26s\tremaining: 6.86s\n",
            "434:\tlearn: 0.0471600\ttotal: 5.27s\tremaining: 6.84s\n",
            "435:\tlearn: 0.0471163\ttotal: 5.28s\tremaining: 6.83s\n",
            "436:\tlearn: 0.0471061\ttotal: 5.29s\tremaining: 6.82s\n",
            "437:\tlearn: 0.0470802\ttotal: 5.3s\tremaining: 6.81s\n",
            "438:\tlearn: 0.0470608\ttotal: 5.32s\tremaining: 6.79s\n",
            "439:\tlearn: 0.0470270\ttotal: 5.33s\tremaining: 6.78s\n",
            "440:\tlearn: 0.0470173\ttotal: 5.34s\tremaining: 6.77s\n",
            "441:\tlearn: 0.0469986\ttotal: 5.35s\tremaining: 6.76s\n",
            "442:\tlearn: 0.0469841\ttotal: 5.36s\tremaining: 6.74s\n",
            "443:\tlearn: 0.0469669\ttotal: 5.37s\tremaining: 6.73s\n",
            "444:\tlearn: 0.0469139\ttotal: 5.39s\tremaining: 6.72s\n",
            "445:\tlearn: 0.0468906\ttotal: 5.4s\tremaining: 6.71s\n",
            "446:\tlearn: 0.0468554\ttotal: 5.41s\tremaining: 6.69s\n",
            "447:\tlearn: 0.0468293\ttotal: 5.42s\tremaining: 6.68s\n",
            "448:\tlearn: 0.0468064\ttotal: 5.43s\tremaining: 6.67s\n",
            "449:\tlearn: 0.0467775\ttotal: 5.45s\tremaining: 6.66s\n",
            "450:\tlearn: 0.0467544\ttotal: 5.46s\tremaining: 6.64s\n",
            "451:\tlearn: 0.0467406\ttotal: 5.47s\tremaining: 6.63s\n",
            "452:\tlearn: 0.0467165\ttotal: 5.48s\tremaining: 6.62s\n",
            "453:\tlearn: 0.0466944\ttotal: 5.49s\tremaining: 6.6s\n",
            "454:\tlearn: 0.0466829\ttotal: 5.5s\tremaining: 6.59s\n",
            "455:\tlearn: 0.0466569\ttotal: 5.51s\tremaining: 6.58s\n",
            "456:\tlearn: 0.0466434\ttotal: 5.52s\tremaining: 6.56s\n",
            "457:\tlearn: 0.0466163\ttotal: 5.54s\tremaining: 6.55s\n",
            "458:\tlearn: 0.0466051\ttotal: 5.55s\tremaining: 6.54s\n",
            "459:\tlearn: 0.0465869\ttotal: 5.56s\tremaining: 6.52s\n",
            "460:\tlearn: 0.0465533\ttotal: 5.57s\tremaining: 6.51s\n",
            "461:\tlearn: 0.0465369\ttotal: 5.58s\tremaining: 6.5s\n",
            "462:\tlearn: 0.0465184\ttotal: 5.59s\tremaining: 6.49s\n",
            "463:\tlearn: 0.0465051\ttotal: 5.6s\tremaining: 6.47s\n",
            "464:\tlearn: 0.0464836\ttotal: 5.62s\tremaining: 6.46s\n",
            "465:\tlearn: 0.0464660\ttotal: 5.63s\tremaining: 6.45s\n",
            "466:\tlearn: 0.0464338\ttotal: 5.64s\tremaining: 6.44s\n",
            "467:\tlearn: 0.0464062\ttotal: 5.66s\tremaining: 6.43s\n",
            "468:\tlearn: 0.0463892\ttotal: 5.67s\tremaining: 6.42s\n",
            "469:\tlearn: 0.0463639\ttotal: 5.69s\tremaining: 6.41s\n",
            "470:\tlearn: 0.0463516\ttotal: 5.7s\tremaining: 6.4s\n",
            "471:\tlearn: 0.0463394\ttotal: 5.71s\tremaining: 6.39s\n",
            "472:\tlearn: 0.0463203\ttotal: 5.72s\tremaining: 6.37s\n",
            "473:\tlearn: 0.0463060\ttotal: 5.73s\tremaining: 6.36s\n",
            "474:\tlearn: 0.0462950\ttotal: 5.74s\tremaining: 6.35s\n",
            "475:\tlearn: 0.0462639\ttotal: 5.75s\tremaining: 6.33s\n",
            "476:\tlearn: 0.0462491\ttotal: 5.76s\tremaining: 6.32s\n",
            "477:\tlearn: 0.0462019\ttotal: 5.78s\tremaining: 6.31s\n",
            "478:\tlearn: 0.0461898\ttotal: 5.79s\tremaining: 6.29s\n",
            "479:\tlearn: 0.0461603\ttotal: 5.8s\tremaining: 6.28s\n",
            "480:\tlearn: 0.0461345\ttotal: 5.81s\tremaining: 6.27s\n",
            "481:\tlearn: 0.0460743\ttotal: 5.82s\tremaining: 6.26s\n",
            "482:\tlearn: 0.0460514\ttotal: 5.83s\tremaining: 6.25s\n",
            "483:\tlearn: 0.0460287\ttotal: 5.85s\tremaining: 6.23s\n",
            "484:\tlearn: 0.0460050\ttotal: 5.86s\tremaining: 6.22s\n",
            "485:\tlearn: 0.0459867\ttotal: 5.87s\tremaining: 6.21s\n",
            "486:\tlearn: 0.0459660\ttotal: 5.88s\tremaining: 6.2s\n",
            "487:\tlearn: 0.0459439\ttotal: 5.89s\tremaining: 6.18s\n",
            "488:\tlearn: 0.0459333\ttotal: 5.91s\tremaining: 6.17s\n",
            "489:\tlearn: 0.0459247\ttotal: 5.92s\tremaining: 6.16s\n",
            "490:\tlearn: 0.0459051\ttotal: 5.93s\tremaining: 6.15s\n",
            "491:\tlearn: 0.0458504\ttotal: 5.94s\tremaining: 6.14s\n",
            "492:\tlearn: 0.0458317\ttotal: 5.96s\tremaining: 6.12s\n",
            "493:\tlearn: 0.0457947\ttotal: 5.97s\tremaining: 6.11s\n",
            "494:\tlearn: 0.0457600\ttotal: 5.98s\tremaining: 6.1s\n",
            "495:\tlearn: 0.0457382\ttotal: 5.99s\tremaining: 6.09s\n",
            "496:\tlearn: 0.0457153\ttotal: 6s\tremaining: 6.07s\n",
            "497:\tlearn: 0.0456929\ttotal: 6.01s\tremaining: 6.06s\n",
            "498:\tlearn: 0.0456644\ttotal: 6.02s\tremaining: 6.05s\n",
            "499:\tlearn: 0.0456465\ttotal: 6.04s\tremaining: 6.04s\n",
            "500:\tlearn: 0.0456236\ttotal: 6.05s\tremaining: 6.02s\n",
            "501:\tlearn: 0.0456013\ttotal: 6.06s\tremaining: 6.01s\n",
            "502:\tlearn: 0.0455861\ttotal: 6.07s\tremaining: 6s\n",
            "503:\tlearn: 0.0455531\ttotal: 6.08s\tremaining: 5.99s\n",
            "504:\tlearn: 0.0455241\ttotal: 6.09s\tremaining: 5.97s\n",
            "505:\tlearn: 0.0455114\ttotal: 6.11s\tremaining: 5.96s\n",
            "506:\tlearn: 0.0454894\ttotal: 6.12s\tremaining: 5.95s\n",
            "507:\tlearn: 0.0454814\ttotal: 6.13s\tremaining: 5.93s\n",
            "508:\tlearn: 0.0454502\ttotal: 6.14s\tremaining: 5.92s\n",
            "509:\tlearn: 0.0454355\ttotal: 6.15s\tremaining: 5.91s\n",
            "510:\tlearn: 0.0454172\ttotal: 6.16s\tremaining: 5.9s\n",
            "511:\tlearn: 0.0453700\ttotal: 6.17s\tremaining: 5.88s\n",
            "512:\tlearn: 0.0453572\ttotal: 6.19s\tremaining: 5.87s\n",
            "513:\tlearn: 0.0453448\ttotal: 6.2s\tremaining: 5.86s\n",
            "514:\tlearn: 0.0453267\ttotal: 6.21s\tremaining: 5.85s\n",
            "515:\tlearn: 0.0453125\ttotal: 6.22s\tremaining: 5.83s\n",
            "516:\tlearn: 0.0452870\ttotal: 6.23s\tremaining: 5.82s\n",
            "517:\tlearn: 0.0452699\ttotal: 6.24s\tremaining: 5.81s\n",
            "518:\tlearn: 0.0452452\ttotal: 6.25s\tremaining: 5.8s\n",
            "519:\tlearn: 0.0452278\ttotal: 6.27s\tremaining: 5.79s\n",
            "520:\tlearn: 0.0452115\ttotal: 6.28s\tremaining: 5.77s\n",
            "521:\tlearn: 0.0451969\ttotal: 6.29s\tremaining: 5.76s\n",
            "522:\tlearn: 0.0451756\ttotal: 6.3s\tremaining: 5.75s\n",
            "523:\tlearn: 0.0451597\ttotal: 6.32s\tremaining: 5.74s\n",
            "524:\tlearn: 0.0451438\ttotal: 6.33s\tremaining: 5.72s\n",
            "525:\tlearn: 0.0451374\ttotal: 6.34s\tremaining: 5.71s\n",
            "526:\tlearn: 0.0451103\ttotal: 6.35s\tremaining: 5.7s\n",
            "527:\tlearn: 0.0450948\ttotal: 6.36s\tremaining: 5.69s\n",
            "528:\tlearn: 0.0450722\ttotal: 6.38s\tremaining: 5.68s\n",
            "529:\tlearn: 0.0450508\ttotal: 6.39s\tremaining: 5.66s\n",
            "530:\tlearn: 0.0450287\ttotal: 6.4s\tremaining: 5.65s\n",
            "531:\tlearn: 0.0450095\ttotal: 6.41s\tremaining: 5.64s\n",
            "532:\tlearn: 0.0449979\ttotal: 6.42s\tremaining: 5.63s\n",
            "533:\tlearn: 0.0449841\ttotal: 6.43s\tremaining: 5.61s\n",
            "534:\tlearn: 0.0449476\ttotal: 6.44s\tremaining: 5.6s\n",
            "535:\tlearn: 0.0449278\ttotal: 6.46s\tremaining: 5.59s\n",
            "536:\tlearn: 0.0449185\ttotal: 6.47s\tremaining: 5.58s\n",
            "537:\tlearn: 0.0449005\ttotal: 6.48s\tremaining: 5.56s\n",
            "538:\tlearn: 0.0448882\ttotal: 6.49s\tremaining: 5.55s\n",
            "539:\tlearn: 0.0448545\ttotal: 6.5s\tremaining: 5.54s\n",
            "540:\tlearn: 0.0448305\ttotal: 6.51s\tremaining: 5.53s\n",
            "541:\tlearn: 0.0448249\ttotal: 6.53s\tremaining: 5.51s\n",
            "542:\tlearn: 0.0448134\ttotal: 6.54s\tremaining: 5.5s\n",
            "543:\tlearn: 0.0447952\ttotal: 6.55s\tremaining: 5.49s\n",
            "544:\tlearn: 0.0447751\ttotal: 6.56s\tremaining: 5.48s\n",
            "545:\tlearn: 0.0447547\ttotal: 6.57s\tremaining: 5.46s\n",
            "546:\tlearn: 0.0447345\ttotal: 6.58s\tremaining: 5.45s\n",
            "547:\tlearn: 0.0447181\ttotal: 6.6s\tremaining: 5.44s\n",
            "548:\tlearn: 0.0447090\ttotal: 6.61s\tremaining: 5.43s\n",
            "549:\tlearn: 0.0446967\ttotal: 6.62s\tremaining: 5.42s\n",
            "550:\tlearn: 0.0446856\ttotal: 6.63s\tremaining: 5.4s\n",
            "551:\tlearn: 0.0446673\ttotal: 6.64s\tremaining: 5.39s\n",
            "552:\tlearn: 0.0446526\ttotal: 6.65s\tremaining: 5.38s\n",
            "553:\tlearn: 0.0446404\ttotal: 6.67s\tremaining: 5.37s\n",
            "554:\tlearn: 0.0446308\ttotal: 6.68s\tremaining: 5.35s\n",
            "555:\tlearn: 0.0445929\ttotal: 6.69s\tremaining: 5.34s\n",
            "556:\tlearn: 0.0445765\ttotal: 6.7s\tremaining: 5.33s\n",
            "557:\tlearn: 0.0445634\ttotal: 6.71s\tremaining: 5.32s\n",
            "558:\tlearn: 0.0445444\ttotal: 6.72s\tremaining: 5.3s\n",
            "559:\tlearn: 0.0445279\ttotal: 6.74s\tremaining: 5.29s\n",
            "560:\tlearn: 0.0445120\ttotal: 6.75s\tremaining: 5.28s\n",
            "561:\tlearn: 0.0444929\ttotal: 6.76s\tremaining: 5.27s\n",
            "562:\tlearn: 0.0444724\ttotal: 6.77s\tremaining: 5.25s\n",
            "563:\tlearn: 0.0444633\ttotal: 6.78s\tremaining: 5.24s\n",
            "564:\tlearn: 0.0444458\ttotal: 6.79s\tremaining: 5.23s\n",
            "565:\tlearn: 0.0444391\ttotal: 6.81s\tremaining: 5.22s\n",
            "566:\tlearn: 0.0444302\ttotal: 6.82s\tremaining: 5.21s\n",
            "567:\tlearn: 0.0444108\ttotal: 6.83s\tremaining: 5.19s\n",
            "568:\tlearn: 0.0443968\ttotal: 6.84s\tremaining: 5.18s\n",
            "569:\tlearn: 0.0443863\ttotal: 6.85s\tremaining: 5.17s\n",
            "570:\tlearn: 0.0443575\ttotal: 6.86s\tremaining: 5.16s\n",
            "571:\tlearn: 0.0443395\ttotal: 6.88s\tremaining: 5.14s\n",
            "572:\tlearn: 0.0443231\ttotal: 6.89s\tremaining: 5.13s\n",
            "573:\tlearn: 0.0442961\ttotal: 6.9s\tremaining: 5.12s\n",
            "574:\tlearn: 0.0442837\ttotal: 6.91s\tremaining: 5.11s\n",
            "575:\tlearn: 0.0442642\ttotal: 6.92s\tremaining: 5.09s\n",
            "576:\tlearn: 0.0442545\ttotal: 6.93s\tremaining: 5.08s\n",
            "577:\tlearn: 0.0442404\ttotal: 6.95s\tremaining: 5.07s\n",
            "578:\tlearn: 0.0442166\ttotal: 6.96s\tremaining: 5.06s\n",
            "579:\tlearn: 0.0442105\ttotal: 6.97s\tremaining: 5.05s\n",
            "580:\tlearn: 0.0441933\ttotal: 6.98s\tremaining: 5.04s\n",
            "581:\tlearn: 0.0441814\ttotal: 6.99s\tremaining: 5.02s\n",
            "582:\tlearn: 0.0441692\ttotal: 7s\tremaining: 5.01s\n",
            "583:\tlearn: 0.0441495\ttotal: 7.02s\tremaining: 5s\n",
            "584:\tlearn: 0.0441252\ttotal: 7.03s\tremaining: 4.99s\n",
            "585:\tlearn: 0.0441134\ttotal: 7.04s\tremaining: 4.97s\n",
            "586:\tlearn: 0.0440979\ttotal: 7.05s\tremaining: 4.96s\n",
            "587:\tlearn: 0.0440916\ttotal: 7.06s\tremaining: 4.95s\n",
            "588:\tlearn: 0.0440637\ttotal: 7.07s\tremaining: 4.94s\n",
            "589:\tlearn: 0.0440474\ttotal: 7.09s\tremaining: 4.92s\n",
            "590:\tlearn: 0.0440245\ttotal: 7.1s\tremaining: 4.91s\n",
            "591:\tlearn: 0.0440043\ttotal: 7.11s\tremaining: 4.9s\n",
            "592:\tlearn: 0.0439908\ttotal: 7.12s\tremaining: 4.89s\n",
            "593:\tlearn: 0.0439762\ttotal: 7.13s\tremaining: 4.88s\n",
            "594:\tlearn: 0.0439698\ttotal: 7.15s\tremaining: 4.86s\n",
            "595:\tlearn: 0.0439697\ttotal: 7.16s\tremaining: 4.85s\n",
            "596:\tlearn: 0.0439667\ttotal: 7.17s\tremaining: 4.84s\n",
            "597:\tlearn: 0.0439578\ttotal: 7.18s\tremaining: 4.82s\n",
            "598:\tlearn: 0.0439403\ttotal: 7.19s\tremaining: 4.81s\n",
            "599:\tlearn: 0.0439050\ttotal: 7.2s\tremaining: 4.8s\n",
            "600:\tlearn: 0.0438960\ttotal: 7.21s\tremaining: 4.79s\n",
            "601:\tlearn: 0.0438828\ttotal: 7.22s\tremaining: 4.78s\n",
            "602:\tlearn: 0.0438767\ttotal: 7.24s\tremaining: 4.76s\n",
            "603:\tlearn: 0.0438553\ttotal: 7.25s\tremaining: 4.75s\n",
            "604:\tlearn: 0.0438315\ttotal: 7.26s\tremaining: 4.74s\n",
            "605:\tlearn: 0.0438142\ttotal: 7.27s\tremaining: 4.73s\n",
            "606:\tlearn: 0.0437943\ttotal: 7.28s\tremaining: 4.71s\n",
            "607:\tlearn: 0.0437796\ttotal: 7.29s\tremaining: 4.7s\n",
            "608:\tlearn: 0.0437695\ttotal: 7.31s\tremaining: 4.69s\n",
            "609:\tlearn: 0.0437604\ttotal: 7.32s\tremaining: 4.68s\n",
            "610:\tlearn: 0.0437406\ttotal: 7.33s\tremaining: 4.67s\n",
            "611:\tlearn: 0.0437225\ttotal: 7.34s\tremaining: 4.66s\n",
            "612:\tlearn: 0.0436961\ttotal: 7.36s\tremaining: 4.64s\n",
            "613:\tlearn: 0.0436751\ttotal: 7.37s\tremaining: 4.63s\n",
            "614:\tlearn: 0.0436627\ttotal: 7.38s\tremaining: 4.62s\n",
            "615:\tlearn: 0.0436465\ttotal: 7.39s\tremaining: 4.61s\n",
            "616:\tlearn: 0.0436301\ttotal: 7.4s\tremaining: 4.59s\n",
            "617:\tlearn: 0.0436221\ttotal: 7.41s\tremaining: 4.58s\n",
            "618:\tlearn: 0.0436073\ttotal: 7.42s\tremaining: 4.57s\n",
            "619:\tlearn: 0.0435835\ttotal: 7.44s\tremaining: 4.56s\n",
            "620:\tlearn: 0.0435721\ttotal: 7.45s\tremaining: 4.55s\n",
            "621:\tlearn: 0.0435667\ttotal: 7.46s\tremaining: 4.53s\n",
            "622:\tlearn: 0.0435538\ttotal: 7.47s\tremaining: 4.52s\n",
            "623:\tlearn: 0.0435309\ttotal: 7.49s\tremaining: 4.51s\n",
            "624:\tlearn: 0.0435262\ttotal: 7.5s\tremaining: 4.5s\n",
            "625:\tlearn: 0.0435081\ttotal: 7.51s\tremaining: 4.49s\n",
            "626:\tlearn: 0.0434938\ttotal: 7.52s\tremaining: 4.47s\n",
            "627:\tlearn: 0.0434780\ttotal: 7.53s\tremaining: 4.46s\n",
            "628:\tlearn: 0.0434521\ttotal: 7.55s\tremaining: 4.45s\n",
            "629:\tlearn: 0.0434333\ttotal: 7.56s\tremaining: 4.44s\n",
            "630:\tlearn: 0.0434190\ttotal: 7.57s\tremaining: 4.43s\n",
            "631:\tlearn: 0.0433919\ttotal: 7.58s\tremaining: 4.41s\n",
            "632:\tlearn: 0.0433824\ttotal: 7.59s\tremaining: 4.4s\n",
            "633:\tlearn: 0.0433771\ttotal: 7.6s\tremaining: 4.39s\n",
            "634:\tlearn: 0.0433598\ttotal: 7.62s\tremaining: 4.38s\n",
            "635:\tlearn: 0.0433435\ttotal: 7.63s\tremaining: 4.37s\n",
            "636:\tlearn: 0.0433272\ttotal: 7.64s\tremaining: 4.35s\n",
            "637:\tlearn: 0.0433168\ttotal: 7.65s\tremaining: 4.34s\n",
            "638:\tlearn: 0.0433043\ttotal: 7.66s\tremaining: 4.33s\n",
            "639:\tlearn: 0.0432940\ttotal: 7.67s\tremaining: 4.32s\n",
            "640:\tlearn: 0.0432770\ttotal: 7.69s\tremaining: 4.3s\n",
            "641:\tlearn: 0.0432712\ttotal: 7.7s\tremaining: 4.29s\n",
            "642:\tlearn: 0.0432640\ttotal: 7.71s\tremaining: 4.28s\n",
            "643:\tlearn: 0.0432500\ttotal: 7.72s\tremaining: 4.27s\n",
            "644:\tlearn: 0.0432376\ttotal: 7.74s\tremaining: 4.26s\n",
            "645:\tlearn: 0.0432008\ttotal: 7.75s\tremaining: 4.24s\n",
            "646:\tlearn: 0.0431862\ttotal: 7.76s\tremaining: 4.23s\n",
            "647:\tlearn: 0.0431740\ttotal: 7.77s\tremaining: 4.22s\n",
            "648:\tlearn: 0.0431472\ttotal: 7.78s\tremaining: 4.21s\n",
            "649:\tlearn: 0.0431379\ttotal: 7.79s\tremaining: 4.2s\n",
            "650:\tlearn: 0.0431071\ttotal: 7.81s\tremaining: 4.18s\n",
            "651:\tlearn: 0.0430848\ttotal: 7.82s\tremaining: 4.17s\n",
            "652:\tlearn: 0.0430728\ttotal: 7.83s\tremaining: 4.16s\n",
            "653:\tlearn: 0.0430654\ttotal: 7.84s\tremaining: 4.15s\n",
            "654:\tlearn: 0.0430476\ttotal: 7.85s\tremaining: 4.14s\n",
            "655:\tlearn: 0.0430407\ttotal: 7.87s\tremaining: 4.13s\n",
            "656:\tlearn: 0.0430099\ttotal: 7.88s\tremaining: 4.11s\n",
            "657:\tlearn: 0.0429847\ttotal: 7.89s\tremaining: 4.1s\n",
            "658:\tlearn: 0.0429646\ttotal: 7.9s\tremaining: 4.09s\n",
            "659:\tlearn: 0.0429496\ttotal: 7.91s\tremaining: 4.08s\n",
            "660:\tlearn: 0.0429304\ttotal: 7.92s\tremaining: 4.06s\n",
            "661:\tlearn: 0.0429132\ttotal: 7.94s\tremaining: 4.05s\n",
            "662:\tlearn: 0.0428963\ttotal: 7.95s\tremaining: 4.04s\n",
            "663:\tlearn: 0.0428788\ttotal: 7.96s\tremaining: 4.03s\n",
            "664:\tlearn: 0.0428538\ttotal: 7.97s\tremaining: 4.02s\n",
            "665:\tlearn: 0.0428396\ttotal: 7.98s\tremaining: 4s\n",
            "666:\tlearn: 0.0428163\ttotal: 8s\tremaining: 3.99s\n",
            "667:\tlearn: 0.0427983\ttotal: 8.01s\tremaining: 3.98s\n",
            "668:\tlearn: 0.0427903\ttotal: 8.02s\tremaining: 3.97s\n",
            "669:\tlearn: 0.0427677\ttotal: 8.03s\tremaining: 3.96s\n",
            "670:\tlearn: 0.0427422\ttotal: 8.04s\tremaining: 3.94s\n",
            "671:\tlearn: 0.0427337\ttotal: 8.06s\tremaining: 3.93s\n",
            "672:\tlearn: 0.0427100\ttotal: 8.07s\tremaining: 3.92s\n",
            "673:\tlearn: 0.0426963\ttotal: 8.08s\tremaining: 3.91s\n",
            "674:\tlearn: 0.0426864\ttotal: 8.09s\tremaining: 3.9s\n",
            "675:\tlearn: 0.0426714\ttotal: 8.1s\tremaining: 3.88s\n",
            "676:\tlearn: 0.0426598\ttotal: 8.12s\tremaining: 3.87s\n",
            "677:\tlearn: 0.0426547\ttotal: 8.13s\tremaining: 3.86s\n",
            "678:\tlearn: 0.0426348\ttotal: 8.14s\tremaining: 3.85s\n",
            "679:\tlearn: 0.0426275\ttotal: 8.15s\tremaining: 3.83s\n",
            "680:\tlearn: 0.0426165\ttotal: 8.16s\tremaining: 3.82s\n",
            "681:\tlearn: 0.0426009\ttotal: 8.18s\tremaining: 3.81s\n",
            "682:\tlearn: 0.0425883\ttotal: 8.19s\tremaining: 3.8s\n",
            "683:\tlearn: 0.0425708\ttotal: 8.2s\tremaining: 3.79s\n",
            "684:\tlearn: 0.0425582\ttotal: 8.21s\tremaining: 3.78s\n",
            "685:\tlearn: 0.0425456\ttotal: 8.22s\tremaining: 3.76s\n",
            "686:\tlearn: 0.0425212\ttotal: 8.23s\tremaining: 3.75s\n",
            "687:\tlearn: 0.0425040\ttotal: 8.25s\tremaining: 3.74s\n",
            "688:\tlearn: 0.0424904\ttotal: 8.26s\tremaining: 3.73s\n",
            "689:\tlearn: 0.0424847\ttotal: 8.27s\tremaining: 3.72s\n",
            "690:\tlearn: 0.0424597\ttotal: 8.28s\tremaining: 3.7s\n",
            "691:\tlearn: 0.0424487\ttotal: 8.29s\tremaining: 3.69s\n",
            "692:\tlearn: 0.0424225\ttotal: 8.31s\tremaining: 3.68s\n",
            "693:\tlearn: 0.0423982\ttotal: 8.32s\tremaining: 3.67s\n",
            "694:\tlearn: 0.0423815\ttotal: 8.34s\tremaining: 3.66s\n",
            "695:\tlearn: 0.0423709\ttotal: 8.35s\tremaining: 3.65s\n",
            "696:\tlearn: 0.0423654\ttotal: 8.36s\tremaining: 3.63s\n",
            "697:\tlearn: 0.0423535\ttotal: 8.37s\tremaining: 3.62s\n",
            "698:\tlearn: 0.0423430\ttotal: 8.38s\tremaining: 3.61s\n",
            "699:\tlearn: 0.0423289\ttotal: 8.39s\tremaining: 3.6s\n",
            "700:\tlearn: 0.0423223\ttotal: 8.41s\tremaining: 3.58s\n",
            "701:\tlearn: 0.0423133\ttotal: 8.42s\tremaining: 3.57s\n",
            "702:\tlearn: 0.0423021\ttotal: 8.43s\tremaining: 3.56s\n",
            "703:\tlearn: 0.0422846\ttotal: 8.44s\tremaining: 3.55s\n",
            "704:\tlearn: 0.0422724\ttotal: 8.45s\tremaining: 3.54s\n",
            "705:\tlearn: 0.0422657\ttotal: 8.46s\tremaining: 3.52s\n",
            "706:\tlearn: 0.0422615\ttotal: 8.48s\tremaining: 3.51s\n",
            "707:\tlearn: 0.0422483\ttotal: 8.49s\tremaining: 3.5s\n",
            "708:\tlearn: 0.0422365\ttotal: 8.5s\tremaining: 3.49s\n",
            "709:\tlearn: 0.0422235\ttotal: 8.51s\tremaining: 3.48s\n",
            "710:\tlearn: 0.0422036\ttotal: 8.53s\tremaining: 3.46s\n",
            "711:\tlearn: 0.0421948\ttotal: 8.54s\tremaining: 3.45s\n",
            "712:\tlearn: 0.0421807\ttotal: 8.55s\tremaining: 3.44s\n",
            "713:\tlearn: 0.0421526\ttotal: 8.56s\tremaining: 3.43s\n",
            "714:\tlearn: 0.0421360\ttotal: 8.57s\tremaining: 3.42s\n",
            "715:\tlearn: 0.0421206\ttotal: 8.59s\tremaining: 3.41s\n",
            "716:\tlearn: 0.0421070\ttotal: 8.6s\tremaining: 3.39s\n",
            "717:\tlearn: 0.0420986\ttotal: 8.61s\tremaining: 3.38s\n",
            "718:\tlearn: 0.0420940\ttotal: 8.62s\tremaining: 3.37s\n",
            "719:\tlearn: 0.0420766\ttotal: 8.63s\tremaining: 3.36s\n",
            "720:\tlearn: 0.0420733\ttotal: 8.65s\tremaining: 3.35s\n",
            "721:\tlearn: 0.0420644\ttotal: 8.66s\tremaining: 3.33s\n",
            "722:\tlearn: 0.0420523\ttotal: 8.67s\tremaining: 3.32s\n",
            "723:\tlearn: 0.0420451\ttotal: 8.68s\tremaining: 3.31s\n",
            "724:\tlearn: 0.0420242\ttotal: 8.7s\tremaining: 3.3s\n",
            "725:\tlearn: 0.0420121\ttotal: 8.71s\tremaining: 3.29s\n",
            "726:\tlearn: 0.0420002\ttotal: 8.72s\tremaining: 3.27s\n",
            "727:\tlearn: 0.0419904\ttotal: 8.73s\tremaining: 3.26s\n",
            "728:\tlearn: 0.0419852\ttotal: 8.74s\tremaining: 3.25s\n",
            "729:\tlearn: 0.0419796\ttotal: 8.75s\tremaining: 3.24s\n",
            "730:\tlearn: 0.0419584\ttotal: 8.77s\tremaining: 3.23s\n",
            "731:\tlearn: 0.0419513\ttotal: 8.78s\tremaining: 3.21s\n",
            "732:\tlearn: 0.0419312\ttotal: 8.79s\tremaining: 3.2s\n",
            "733:\tlearn: 0.0419061\ttotal: 8.8s\tremaining: 3.19s\n",
            "734:\tlearn: 0.0418936\ttotal: 8.81s\tremaining: 3.18s\n",
            "735:\tlearn: 0.0418709\ttotal: 8.83s\tremaining: 3.17s\n",
            "736:\tlearn: 0.0418505\ttotal: 8.84s\tremaining: 3.15s\n",
            "737:\tlearn: 0.0418417\ttotal: 8.85s\tremaining: 3.14s\n",
            "738:\tlearn: 0.0418285\ttotal: 8.86s\tremaining: 3.13s\n",
            "739:\tlearn: 0.0418112\ttotal: 8.88s\tremaining: 3.12s\n",
            "740:\tlearn: 0.0417930\ttotal: 8.89s\tremaining: 3.11s\n",
            "741:\tlearn: 0.0417872\ttotal: 8.9s\tremaining: 3.09s\n",
            "742:\tlearn: 0.0417711\ttotal: 8.91s\tremaining: 3.08s\n",
            "743:\tlearn: 0.0417541\ttotal: 8.92s\tremaining: 3.07s\n",
            "744:\tlearn: 0.0417475\ttotal: 8.94s\tremaining: 3.06s\n",
            "745:\tlearn: 0.0417312\ttotal: 8.95s\tremaining: 3.05s\n",
            "746:\tlearn: 0.0417128\ttotal: 8.96s\tremaining: 3.03s\n",
            "747:\tlearn: 0.0416953\ttotal: 8.97s\tremaining: 3.02s\n",
            "748:\tlearn: 0.0416807\ttotal: 8.98s\tremaining: 3.01s\n",
            "749:\tlearn: 0.0416600\ttotal: 8.99s\tremaining: 3s\n",
            "750:\tlearn: 0.0416477\ttotal: 9.01s\tremaining: 2.99s\n",
            "751:\tlearn: 0.0416477\ttotal: 9.02s\tremaining: 2.97s\n",
            "752:\tlearn: 0.0416389\ttotal: 9.03s\tremaining: 2.96s\n",
            "753:\tlearn: 0.0416306\ttotal: 9.04s\tremaining: 2.95s\n",
            "754:\tlearn: 0.0416024\ttotal: 9.05s\tremaining: 2.94s\n",
            "755:\tlearn: 0.0415931\ttotal: 9.06s\tremaining: 2.92s\n",
            "756:\tlearn: 0.0415858\ttotal: 9.08s\tremaining: 2.91s\n",
            "757:\tlearn: 0.0415705\ttotal: 9.09s\tremaining: 2.9s\n",
            "758:\tlearn: 0.0415582\ttotal: 9.1s\tremaining: 2.89s\n",
            "759:\tlearn: 0.0415388\ttotal: 9.11s\tremaining: 2.88s\n",
            "760:\tlearn: 0.0415316\ttotal: 9.13s\tremaining: 2.87s\n",
            "761:\tlearn: 0.0415141\ttotal: 9.14s\tremaining: 2.85s\n",
            "762:\tlearn: 0.0415045\ttotal: 9.15s\tremaining: 2.84s\n",
            "763:\tlearn: 0.0414988\ttotal: 9.16s\tremaining: 2.83s\n",
            "764:\tlearn: 0.0414863\ttotal: 9.17s\tremaining: 2.82s\n",
            "765:\tlearn: 0.0414863\ttotal: 9.18s\tremaining: 2.81s\n",
            "766:\tlearn: 0.0414862\ttotal: 9.19s\tremaining: 2.79s\n",
            "767:\tlearn: 0.0414862\ttotal: 9.2s\tremaining: 2.78s\n",
            "768:\tlearn: 0.0414682\ttotal: 9.21s\tremaining: 2.77s\n",
            "769:\tlearn: 0.0414570\ttotal: 9.22s\tremaining: 2.75s\n",
            "770:\tlearn: 0.0414371\ttotal: 9.24s\tremaining: 2.74s\n",
            "771:\tlearn: 0.0414225\ttotal: 9.25s\tremaining: 2.73s\n",
            "772:\tlearn: 0.0414095\ttotal: 9.26s\tremaining: 2.72s\n",
            "773:\tlearn: 0.0413873\ttotal: 9.27s\tremaining: 2.71s\n",
            "774:\tlearn: 0.0413716\ttotal: 9.29s\tremaining: 2.69s\n",
            "775:\tlearn: 0.0413650\ttotal: 9.3s\tremaining: 2.68s\n",
            "776:\tlearn: 0.0413566\ttotal: 9.31s\tremaining: 2.67s\n",
            "777:\tlearn: 0.0413355\ttotal: 9.32s\tremaining: 2.66s\n",
            "778:\tlearn: 0.0413164\ttotal: 9.33s\tremaining: 2.65s\n",
            "779:\tlearn: 0.0413088\ttotal: 9.35s\tremaining: 2.64s\n",
            "780:\tlearn: 0.0412957\ttotal: 9.36s\tremaining: 2.62s\n",
            "781:\tlearn: 0.0412881\ttotal: 9.37s\tremaining: 2.61s\n",
            "782:\tlearn: 0.0412790\ttotal: 9.38s\tremaining: 2.6s\n",
            "783:\tlearn: 0.0412717\ttotal: 9.39s\tremaining: 2.59s\n",
            "784:\tlearn: 0.0412483\ttotal: 9.41s\tremaining: 2.58s\n",
            "785:\tlearn: 0.0412406\ttotal: 9.42s\tremaining: 2.56s\n",
            "786:\tlearn: 0.0412321\ttotal: 9.43s\tremaining: 2.55s\n",
            "787:\tlearn: 0.0412293\ttotal: 9.44s\tremaining: 2.54s\n",
            "788:\tlearn: 0.0412183\ttotal: 9.46s\tremaining: 2.53s\n",
            "789:\tlearn: 0.0412056\ttotal: 9.47s\tremaining: 2.52s\n",
            "790:\tlearn: 0.0411857\ttotal: 9.48s\tremaining: 2.5s\n",
            "791:\tlearn: 0.0411681\ttotal: 9.49s\tremaining: 2.49s\n",
            "792:\tlearn: 0.0411591\ttotal: 9.5s\tremaining: 2.48s\n",
            "793:\tlearn: 0.0411591\ttotal: 9.51s\tremaining: 2.47s\n",
            "794:\tlearn: 0.0411590\ttotal: 9.52s\tremaining: 2.46s\n",
            "795:\tlearn: 0.0411502\ttotal: 9.54s\tremaining: 2.44s\n",
            "796:\tlearn: 0.0411424\ttotal: 9.55s\tremaining: 2.43s\n",
            "797:\tlearn: 0.0411352\ttotal: 9.56s\tremaining: 2.42s\n",
            "798:\tlearn: 0.0411209\ttotal: 9.57s\tremaining: 2.41s\n",
            "799:\tlearn: 0.0411026\ttotal: 9.58s\tremaining: 2.4s\n",
            "800:\tlearn: 0.0410935\ttotal: 9.59s\tremaining: 2.38s\n",
            "801:\tlearn: 0.0410789\ttotal: 9.61s\tremaining: 2.37s\n",
            "802:\tlearn: 0.0410614\ttotal: 9.62s\tremaining: 2.36s\n",
            "803:\tlearn: 0.0410501\ttotal: 9.63s\tremaining: 2.35s\n",
            "804:\tlearn: 0.0410233\ttotal: 9.64s\tremaining: 2.34s\n",
            "805:\tlearn: 0.0410104\ttotal: 9.65s\tremaining: 2.32s\n",
            "806:\tlearn: 0.0409895\ttotal: 9.67s\tremaining: 2.31s\n",
            "807:\tlearn: 0.0409802\ttotal: 9.68s\tremaining: 2.3s\n",
            "808:\tlearn: 0.0409738\ttotal: 9.69s\tremaining: 2.29s\n",
            "809:\tlearn: 0.0409643\ttotal: 9.71s\tremaining: 2.28s\n",
            "810:\tlearn: 0.0409498\ttotal: 9.72s\tremaining: 2.27s\n",
            "811:\tlearn: 0.0409391\ttotal: 9.73s\tremaining: 2.25s\n",
            "812:\tlearn: 0.0409159\ttotal: 9.74s\tremaining: 2.24s\n",
            "813:\tlearn: 0.0409052\ttotal: 9.76s\tremaining: 2.23s\n",
            "814:\tlearn: 0.0408904\ttotal: 9.77s\tremaining: 2.22s\n",
            "815:\tlearn: 0.0408904\ttotal: 9.78s\tremaining: 2.2s\n",
            "816:\tlearn: 0.0408838\ttotal: 9.79s\tremaining: 2.19s\n",
            "817:\tlearn: 0.0408685\ttotal: 9.8s\tremaining: 2.18s\n",
            "818:\tlearn: 0.0408685\ttotal: 9.81s\tremaining: 2.17s\n",
            "819:\tlearn: 0.0408684\ttotal: 9.82s\tremaining: 2.16s\n",
            "820:\tlearn: 0.0408684\ttotal: 9.83s\tremaining: 2.14s\n",
            "821:\tlearn: 0.0408684\ttotal: 9.84s\tremaining: 2.13s\n",
            "822:\tlearn: 0.0408684\ttotal: 9.85s\tremaining: 2.12s\n",
            "823:\tlearn: 0.0408539\ttotal: 9.87s\tremaining: 2.11s\n",
            "824:\tlearn: 0.0408537\ttotal: 9.88s\tremaining: 2.09s\n",
            "825:\tlearn: 0.0408453\ttotal: 9.89s\tremaining: 2.08s\n",
            "826:\tlearn: 0.0408386\ttotal: 9.9s\tremaining: 2.07s\n",
            "827:\tlearn: 0.0408239\ttotal: 9.91s\tremaining: 2.06s\n",
            "828:\tlearn: 0.0408145\ttotal: 9.92s\tremaining: 2.05s\n",
            "829:\tlearn: 0.0408019\ttotal: 9.94s\tremaining: 2.04s\n",
            "830:\tlearn: 0.0407812\ttotal: 9.95s\tremaining: 2.02s\n",
            "831:\tlearn: 0.0407623\ttotal: 9.96s\tremaining: 2.01s\n",
            "832:\tlearn: 0.0407458\ttotal: 9.97s\tremaining: 2s\n",
            "833:\tlearn: 0.0407345\ttotal: 9.98s\tremaining: 1.99s\n",
            "834:\tlearn: 0.0407239\ttotal: 10s\tremaining: 1.98s\n",
            "835:\tlearn: 0.0406945\ttotal: 10s\tremaining: 1.96s\n",
            "836:\tlearn: 0.0406837\ttotal: 10s\tremaining: 1.95s\n",
            "837:\tlearn: 0.0406646\ttotal: 10s\tremaining: 1.94s\n",
            "838:\tlearn: 0.0406541\ttotal: 10s\tremaining: 1.93s\n",
            "839:\tlearn: 0.0406320\ttotal: 10.1s\tremaining: 1.92s\n",
            "840:\tlearn: 0.0406153\ttotal: 10.1s\tremaining: 1.9s\n",
            "841:\tlearn: 0.0406096\ttotal: 10.1s\tremaining: 1.89s\n",
            "842:\tlearn: 0.0405969\ttotal: 10.1s\tremaining: 1.88s\n",
            "843:\tlearn: 0.0405856\ttotal: 10.1s\tremaining: 1.87s\n",
            "844:\tlearn: 0.0405655\ttotal: 10.1s\tremaining: 1.86s\n",
            "845:\tlearn: 0.0405506\ttotal: 10.1s\tremaining: 1.84s\n",
            "846:\tlearn: 0.0405279\ttotal: 10.1s\tremaining: 1.83s\n",
            "847:\tlearn: 0.0405185\ttotal: 10.2s\tremaining: 1.82s\n",
            "848:\tlearn: 0.0404975\ttotal: 10.2s\tremaining: 1.81s\n",
            "849:\tlearn: 0.0404859\ttotal: 10.2s\tremaining: 1.8s\n",
            "850:\tlearn: 0.0404858\ttotal: 10.2s\tremaining: 1.78s\n",
            "851:\tlearn: 0.0404724\ttotal: 10.2s\tremaining: 1.77s\n",
            "852:\tlearn: 0.0404559\ttotal: 10.2s\tremaining: 1.76s\n",
            "853:\tlearn: 0.0404475\ttotal: 10.2s\tremaining: 1.75s\n",
            "854:\tlearn: 0.0404342\ttotal: 10.2s\tremaining: 1.74s\n",
            "855:\tlearn: 0.0404262\ttotal: 10.3s\tremaining: 1.73s\n",
            "856:\tlearn: 0.0404067\ttotal: 10.3s\tremaining: 1.71s\n",
            "857:\tlearn: 0.0404009\ttotal: 10.3s\tremaining: 1.7s\n",
            "858:\tlearn: 0.0403849\ttotal: 10.3s\tremaining: 1.69s\n",
            "859:\tlearn: 0.0403750\ttotal: 10.3s\tremaining: 1.68s\n",
            "860:\tlearn: 0.0403750\ttotal: 10.3s\tremaining: 1.67s\n",
            "861:\tlearn: 0.0403669\ttotal: 10.3s\tremaining: 1.65s\n",
            "862:\tlearn: 0.0403543\ttotal: 10.3s\tremaining: 1.64s\n",
            "863:\tlearn: 0.0403464\ttotal: 10.4s\tremaining: 1.63s\n",
            "864:\tlearn: 0.0403417\ttotal: 10.4s\tremaining: 1.62s\n",
            "865:\tlearn: 0.0403299\ttotal: 10.4s\tremaining: 1.6s\n",
            "866:\tlearn: 0.0403143\ttotal: 10.4s\tremaining: 1.59s\n",
            "867:\tlearn: 0.0402979\ttotal: 10.4s\tremaining: 1.58s\n",
            "868:\tlearn: 0.0402944\ttotal: 10.4s\tremaining: 1.57s\n",
            "869:\tlearn: 0.0402863\ttotal: 10.4s\tremaining: 1.56s\n",
            "870:\tlearn: 0.0402861\ttotal: 10.4s\tremaining: 1.54s\n",
            "871:\tlearn: 0.0402688\ttotal: 10.4s\tremaining: 1.53s\n",
            "872:\tlearn: 0.0402546\ttotal: 10.5s\tremaining: 1.52s\n",
            "873:\tlearn: 0.0402452\ttotal: 10.5s\tremaining: 1.51s\n",
            "874:\tlearn: 0.0402282\ttotal: 10.5s\tremaining: 1.5s\n",
            "875:\tlearn: 0.0402151\ttotal: 10.5s\tremaining: 1.49s\n",
            "876:\tlearn: 0.0402086\ttotal: 10.5s\tremaining: 1.47s\n",
            "877:\tlearn: 0.0402085\ttotal: 10.5s\tremaining: 1.46s\n",
            "878:\tlearn: 0.0401949\ttotal: 10.5s\tremaining: 1.45s\n",
            "879:\tlearn: 0.0401945\ttotal: 10.5s\tremaining: 1.44s\n",
            "880:\tlearn: 0.0401900\ttotal: 10.6s\tremaining: 1.43s\n",
            "881:\tlearn: 0.0401807\ttotal: 10.6s\tremaining: 1.41s\n",
            "882:\tlearn: 0.0401726\ttotal: 10.6s\tremaining: 1.4s\n",
            "883:\tlearn: 0.0401542\ttotal: 10.6s\tremaining: 1.39s\n",
            "884:\tlearn: 0.0401373\ttotal: 10.6s\tremaining: 1.38s\n",
            "885:\tlearn: 0.0401105\ttotal: 10.6s\tremaining: 1.37s\n",
            "886:\tlearn: 0.0400851\ttotal: 10.6s\tremaining: 1.35s\n",
            "887:\tlearn: 0.0400712\ttotal: 10.6s\tremaining: 1.34s\n",
            "888:\tlearn: 0.0400566\ttotal: 10.7s\tremaining: 1.33s\n",
            "889:\tlearn: 0.0400483\ttotal: 10.7s\tremaining: 1.32s\n",
            "890:\tlearn: 0.0400374\ttotal: 10.7s\tremaining: 1.31s\n",
            "891:\tlearn: 0.0400315\ttotal: 10.7s\tremaining: 1.29s\n",
            "892:\tlearn: 0.0400162\ttotal: 10.7s\tremaining: 1.28s\n",
            "893:\tlearn: 0.0400051\ttotal: 10.7s\tremaining: 1.27s\n",
            "894:\tlearn: 0.0399877\ttotal: 10.7s\tremaining: 1.26s\n",
            "895:\tlearn: 0.0399729\ttotal: 10.7s\tremaining: 1.25s\n",
            "896:\tlearn: 0.0399729\ttotal: 10.8s\tremaining: 1.23s\n",
            "897:\tlearn: 0.0399729\ttotal: 10.8s\tremaining: 1.22s\n",
            "898:\tlearn: 0.0399728\ttotal: 10.8s\tremaining: 1.21s\n",
            "899:\tlearn: 0.0399596\ttotal: 10.8s\tremaining: 1.2s\n",
            "900:\tlearn: 0.0399488\ttotal: 10.8s\tremaining: 1.19s\n",
            "901:\tlearn: 0.0399264\ttotal: 10.8s\tremaining: 1.17s\n",
            "902:\tlearn: 0.0399149\ttotal: 10.8s\tremaining: 1.16s\n",
            "903:\tlearn: 0.0399058\ttotal: 10.8s\tremaining: 1.15s\n",
            "904:\tlearn: 0.0398952\ttotal: 10.8s\tremaining: 1.14s\n",
            "905:\tlearn: 0.0398841\ttotal: 10.9s\tremaining: 1.13s\n",
            "906:\tlearn: 0.0398803\ttotal: 10.9s\tremaining: 1.11s\n",
            "907:\tlearn: 0.0398709\ttotal: 10.9s\tremaining: 1.1s\n",
            "908:\tlearn: 0.0398561\ttotal: 10.9s\tremaining: 1.09s\n",
            "909:\tlearn: 0.0398478\ttotal: 10.9s\tremaining: 1.08s\n",
            "910:\tlearn: 0.0398281\ttotal: 10.9s\tremaining: 1.07s\n",
            "911:\tlearn: 0.0398103\ttotal: 10.9s\tremaining: 1.05s\n",
            "912:\tlearn: 0.0398001\ttotal: 10.9s\tremaining: 1.04s\n",
            "913:\tlearn: 0.0397887\ttotal: 11s\tremaining: 1.03s\n",
            "914:\tlearn: 0.0397826\ttotal: 11s\tremaining: 1.02s\n",
            "915:\tlearn: 0.0397735\ttotal: 11s\tremaining: 1.01s\n",
            "916:\tlearn: 0.0397623\ttotal: 11s\tremaining: 995ms\n",
            "917:\tlearn: 0.0397477\ttotal: 11s\tremaining: 983ms\n",
            "918:\tlearn: 0.0397399\ttotal: 11s\tremaining: 971ms\n",
            "919:\tlearn: 0.0397254\ttotal: 11s\tremaining: 959ms\n",
            "920:\tlearn: 0.0397121\ttotal: 11s\tremaining: 947ms\n",
            "921:\tlearn: 0.0397081\ttotal: 11.1s\tremaining: 935ms\n",
            "922:\tlearn: 0.0397028\ttotal: 11.1s\tremaining: 923ms\n",
            "923:\tlearn: 0.0396983\ttotal: 11.1s\tremaining: 911ms\n",
            "924:\tlearn: 0.0396810\ttotal: 11.1s\tremaining: 899ms\n",
            "925:\tlearn: 0.0396717\ttotal: 11.1s\tremaining: 887ms\n",
            "926:\tlearn: 0.0396483\ttotal: 11.1s\tremaining: 876ms\n",
            "927:\tlearn: 0.0396456\ttotal: 11.1s\tremaining: 864ms\n",
            "928:\tlearn: 0.0396286\ttotal: 11.1s\tremaining: 852ms\n",
            "929:\tlearn: 0.0396194\ttotal: 11.2s\tremaining: 840ms\n",
            "930:\tlearn: 0.0396051\ttotal: 11.2s\tremaining: 828ms\n",
            "931:\tlearn: 0.0395982\ttotal: 11.2s\tremaining: 816ms\n",
            "932:\tlearn: 0.0395876\ttotal: 11.2s\tremaining: 804ms\n",
            "933:\tlearn: 0.0395777\ttotal: 11.2s\tremaining: 792ms\n",
            "934:\tlearn: 0.0395708\ttotal: 11.2s\tremaining: 780ms\n",
            "935:\tlearn: 0.0395630\ttotal: 11.2s\tremaining: 768ms\n",
            "936:\tlearn: 0.0395549\ttotal: 11.2s\tremaining: 756ms\n",
            "937:\tlearn: 0.0395394\ttotal: 11.3s\tremaining: 744ms\n",
            "938:\tlearn: 0.0395271\ttotal: 11.3s\tremaining: 732ms\n",
            "939:\tlearn: 0.0395222\ttotal: 11.3s\tremaining: 720ms\n",
            "940:\tlearn: 0.0394967\ttotal: 11.3s\tremaining: 708ms\n",
            "941:\tlearn: 0.0394868\ttotal: 11.3s\tremaining: 696ms\n",
            "942:\tlearn: 0.0394838\ttotal: 11.3s\tremaining: 684ms\n",
            "943:\tlearn: 0.0394758\ttotal: 11.3s\tremaining: 672ms\n",
            "944:\tlearn: 0.0394667\ttotal: 11.3s\tremaining: 660ms\n",
            "945:\tlearn: 0.0394513\ttotal: 11.4s\tremaining: 648ms\n",
            "946:\tlearn: 0.0394397\ttotal: 11.4s\tremaining: 636ms\n",
            "947:\tlearn: 0.0394339\ttotal: 11.4s\tremaining: 624ms\n",
            "948:\tlearn: 0.0394153\ttotal: 11.4s\tremaining: 612ms\n",
            "949:\tlearn: 0.0394078\ttotal: 11.4s\tremaining: 600ms\n",
            "950:\tlearn: 0.0394020\ttotal: 11.4s\tremaining: 588ms\n",
            "951:\tlearn: 0.0393932\ttotal: 11.4s\tremaining: 576ms\n",
            "952:\tlearn: 0.0393885\ttotal: 11.4s\tremaining: 564ms\n",
            "953:\tlearn: 0.0393809\ttotal: 11.5s\tremaining: 552ms\n",
            "954:\tlearn: 0.0393728\ttotal: 11.5s\tremaining: 540ms\n",
            "955:\tlearn: 0.0393494\ttotal: 11.5s\tremaining: 528ms\n",
            "956:\tlearn: 0.0393301\ttotal: 11.5s\tremaining: 516ms\n",
            "957:\tlearn: 0.0393228\ttotal: 11.5s\tremaining: 504ms\n",
            "958:\tlearn: 0.0393127\ttotal: 11.5s\tremaining: 492ms\n",
            "959:\tlearn: 0.0392980\ttotal: 11.5s\tremaining: 480ms\n",
            "960:\tlearn: 0.0392882\ttotal: 11.5s\tremaining: 468ms\n",
            "961:\tlearn: 0.0392755\ttotal: 11.6s\tremaining: 456ms\n",
            "962:\tlearn: 0.0392709\ttotal: 11.6s\tremaining: 444ms\n",
            "963:\tlearn: 0.0392538\ttotal: 11.6s\tremaining: 432ms\n",
            "964:\tlearn: 0.0392538\ttotal: 11.6s\tremaining: 420ms\n",
            "965:\tlearn: 0.0392510\ttotal: 11.6s\tremaining: 408ms\n",
            "966:\tlearn: 0.0392269\ttotal: 11.6s\tremaining: 396ms\n",
            "967:\tlearn: 0.0392205\ttotal: 11.6s\tremaining: 384ms\n",
            "968:\tlearn: 0.0392122\ttotal: 11.6s\tremaining: 372ms\n",
            "969:\tlearn: 0.0391988\ttotal: 11.6s\tremaining: 360ms\n",
            "970:\tlearn: 0.0391826\ttotal: 11.7s\tremaining: 348ms\n",
            "971:\tlearn: 0.0391744\ttotal: 11.7s\tremaining: 336ms\n",
            "972:\tlearn: 0.0391688\ttotal: 11.7s\tremaining: 324ms\n",
            "973:\tlearn: 0.0391688\ttotal: 11.7s\tremaining: 312ms\n",
            "974:\tlearn: 0.0391688\ttotal: 11.7s\tremaining: 300ms\n",
            "975:\tlearn: 0.0391688\ttotal: 11.7s\tremaining: 288ms\n",
            "976:\tlearn: 0.0391687\ttotal: 11.7s\tremaining: 276ms\n",
            "977:\tlearn: 0.0391687\ttotal: 11.7s\tremaining: 264ms\n",
            "978:\tlearn: 0.0391687\ttotal: 11.8s\tremaining: 252ms\n",
            "979:\tlearn: 0.0391687\ttotal: 11.8s\tremaining: 240ms\n",
            "980:\tlearn: 0.0391687\ttotal: 11.8s\tremaining: 228ms\n",
            "981:\tlearn: 0.0391686\ttotal: 11.8s\tremaining: 216ms\n",
            "982:\tlearn: 0.0391686\ttotal: 11.8s\tremaining: 204ms\n",
            "983:\tlearn: 0.0391686\ttotal: 11.8s\tremaining: 192ms\n",
            "984:\tlearn: 0.0391686\ttotal: 11.8s\tremaining: 180ms\n",
            "985:\tlearn: 0.0391686\ttotal: 11.8s\tremaining: 168ms\n",
            "986:\tlearn: 0.0391686\ttotal: 11.8s\tremaining: 156ms\n",
            "987:\tlearn: 0.0391685\ttotal: 11.8s\tremaining: 144ms\n",
            "988:\tlearn: 0.0391685\ttotal: 11.9s\tremaining: 132ms\n",
            "989:\tlearn: 0.0391685\ttotal: 11.9s\tremaining: 120ms\n",
            "990:\tlearn: 0.0391685\ttotal: 11.9s\tremaining: 108ms\n",
            "991:\tlearn: 0.0391685\ttotal: 11.9s\tremaining: 95.9ms\n",
            "992:\tlearn: 0.0391685\ttotal: 11.9s\tremaining: 83.9ms\n",
            "993:\tlearn: 0.0391685\ttotal: 11.9s\tremaining: 71.9ms\n",
            "994:\tlearn: 0.0391685\ttotal: 11.9s\tremaining: 59.9ms\n",
            "995:\tlearn: 0.0391584\ttotal: 11.9s\tremaining: 47.9ms\n",
            "996:\tlearn: 0.0391555\ttotal: 11.9s\tremaining: 35.9ms\n",
            "997:\tlearn: 0.0391397\ttotal: 12s\tremaining: 24ms\n",
            "998:\tlearn: 0.0391271\ttotal: 12s\tremaining: 12ms\n",
            "999:\tlearn: 0.0391137\ttotal: 12s\tremaining: 0us\n",
            "Accuracy: 0.97045\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98     18292\n",
            "           1       0.94      0.70      0.80      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.96      0.85      0.89     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Create catboot classifer\n",
        "catboost_model=CatBoostClassifier()\n",
        "#Train the model\n",
        "catboost_model.fit(X_train_res,y_train_res)\n",
        "#Make Predictions\n",
        "catboost_predictions=catboost_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, catboost_predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, catboost_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhZEERJ9f23q"
      },
      "source": [
        "XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL2DLjBHf2Q5",
        "outputId": "7acb021b-2e8f-456c-f962-bdd4fefd59fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9698\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     18292\n",
            "           1       0.91      0.71      0.80      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.94      0.85      0.89     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#create XGBoost regressor\n",
        "xgboost_model=xgb.XGBClassifier()\n",
        "#Train the model\n",
        "xgboost_model.fit(X_train_res,y_train_res)\n",
        "#Make predictions\n",
        "xgboost_predictions=xgboost_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, xgboost_predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, xgboost_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31WeCvcOhf-p"
      },
      "source": [
        "LIGHTGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNcafjY9hfTE",
        "outputId": "5ee3faec-d064-42d4-94cc-eac339a13a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 73208, number of negative: 73208\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1285\n",
            "[LightGBM] [Info] Number of data points in the train set: 146416, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Accuracy: 0.97075\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98     18292\n",
            "           1       0.94      0.70      0.80      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.96      0.85      0.89     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vrbk2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
        "lgb_model.fit(X_train_res, y_train_res)\n",
        "y_pred = lgb_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test,y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNP77oDWmD3R"
      },
      "source": [
        "ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RdlZgly3mC24"
      },
      "outputs": [],
      "source": [
        "#Initialising the ANN\n",
        "classifier=Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QbqV266ymwXq"
      },
      "outputs": [],
      "source": [
        "#Adding the input layer and first hidden layer\n",
        "classifier.add(Dense(units=13))#Unit is known as Feature we want to 14-1=13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yXS8nlz7m04E"
      },
      "outputs": [],
      "source": [
        "#Adding the first hidden layer and second hidden layer\n",
        "classifier.add(Dense(units=6,activation=\"relu\"))\n",
        "classifier.add(Dense(units=10,activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GaTe9hppm3h2"
      },
      "outputs": [],
      "source": [
        "#Adding output layer\n",
        "classifier.add(Dense(units=1,activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9y_s5Ietm6ru"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tsKl3C6Rm9c0",
        "outputId": "84e77e77-9003-47a4-d0de-6c59d3cd79b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8733 - loss: 0.3038 - val_accuracy: 0.7846 - val_loss: 0.4171\n",
            "Epoch 2/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2111 - val_accuracy: 0.8091 - val_loss: 0.3611\n",
            "Epoch 3/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.1967 - val_accuracy: 0.7930 - val_loss: 0.3771\n",
            "Epoch 4/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.1925 - val_accuracy: 0.8185 - val_loss: 0.3376\n",
            "Epoch 5/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.1912 - val_accuracy: 0.8091 - val_loss: 0.3554\n",
            "Epoch 6/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.1883 - val_accuracy: 0.8195 - val_loss: 0.3359\n",
            "Epoch 7/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.1894 - val_accuracy: 0.8324 - val_loss: 0.3185\n",
            "Epoch 8/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.1875 - val_accuracy: 0.8118 - val_loss: 0.3482\n",
            "Epoch 9/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.1883 - val_accuracy: 0.8205 - val_loss: 0.3332\n",
            "Epoch 10/10\n",
            "\u001b[1m3203/3203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.1852 - val_accuracy: 0.8129 - val_loss: 0.3432\n"
          ]
        }
      ],
      "source": [
        "model_history = classifier.fit(X_train_res, y_train_res, validation_split=0.30, batch_size=32, epochs=10) #validation means random traning 30% data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clWyOEz8nPWn"
      },
      "source": [
        "Predict and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOGiPQsDm_vx",
        "outputId": "39ce5c42-2acf-4ce8-9585-572bc786945a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step\n"
          ]
        }
      ],
      "source": [
        "#Part 3-Making the predictions and evaluating the model\n",
        "#Predicting the test set result\n",
        "y_pred=classifier.predict(X_test)\n",
        "y_pred_thresholded=(y_pred>0.5).astype(int)#Thershold value 0.5 (greater than 0.5 yes and less means no) & test data has run 100 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH1izLObnEd1",
        "outputId": "36b8d6dc-f2bd-4637-b088-063831804577"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.93755"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "df=confusion_matrix(y_test,y_pred_thresholded)\n",
        "df\n",
        "#Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_test,y_pred_thresholded)\n",
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CfElzoZneYY",
        "outputId": "d501acb7-fea8-40cb-9e69-411a05d5e23e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(80000, 8)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bAvnTzUniOI"
      },
      "source": [
        "Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5R6uzk2Wnh63",
        "outputId": "d38634b1-4232-4a4e-da39-916aded58a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vrbk2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "C:\\Users\\vrbk2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2228 - val_accuracy: 0.9603 - val_loss: 0.1117\n",
            "Epoch 2/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9597 - loss: 0.1196 - val_accuracy: 0.9638 - val_loss: 0.1020\n",
            "Epoch 3/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9629 - loss: 0.1082 - val_accuracy: 0.9665 - val_loss: 0.0954\n",
            "Epoch 4/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1022 - val_accuracy: 0.9691 - val_loss: 0.0925\n",
            "Epoch 5/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.0961 - val_accuracy: 0.9694 - val_loss: 0.0897\n",
            "Epoch 6/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0915 - val_accuracy: 0.9707 - val_loss: 0.0877\n",
            "Epoch 7/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0903 - val_accuracy: 0.9704 - val_loss: 0.0875\n",
            "Epoch 8/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0908 - val_accuracy: 0.9696 - val_loss: 0.0888\n",
            "Epoch 9/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0876 - val_accuracy: 0.9710 - val_loss: 0.0873\n",
            "Epoch 10/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.0889 - val_accuracy: 0.9702 - val_loss: 0.0878\n",
            "Epoch 11/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0907 - val_accuracy: 0.9710 - val_loss: 0.0865\n",
            "Epoch 12/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.0886 - val_accuracy: 0.9682 - val_loss: 0.0900\n",
            "Epoch 13/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0883 - val_accuracy: 0.9704 - val_loss: 0.0876\n",
            "Epoch 14/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0854 - val_accuracy: 0.9701 - val_loss: 0.0859\n",
            "Epoch 15/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0853 - val_accuracy: 0.9704 - val_loss: 0.0870\n",
            "Epoch 16/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0874 - val_accuracy: 0.9712 - val_loss: 0.0858\n",
            "Epoch 17/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0881 - val_accuracy: 0.9703 - val_loss: 0.0868\n",
            "Epoch 18/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0876 - val_accuracy: 0.9711 - val_loss: 0.0854\n",
            "Epoch 19/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0855 - val_accuracy: 0.9711 - val_loss: 0.0860\n",
            "Epoch 20/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0848 - val_accuracy: 0.9707 - val_loss: 0.0857\n",
            "Epoch 21/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0885 - val_accuracy: 0.9704 - val_loss: 0.0866\n",
            "Epoch 22/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.0863 - val_accuracy: 0.9712 - val_loss: 0.0853\n",
            "Epoch 23/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.0878 - val_accuracy: 0.9689 - val_loss: 0.0892\n",
            "Epoch 24/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0867 - val_accuracy: 0.9692 - val_loss: 0.0940\n",
            "Epoch 25/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0877 - val_accuracy: 0.9711 - val_loss: 0.0857\n",
            "Epoch 26/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.0848 - val_accuracy: 0.9711 - val_loss: 0.0852\n",
            "Epoch 27/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0856 - val_accuracy: 0.9711 - val_loss: 0.0858\n",
            "Epoch 28/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0846 - val_accuracy: 0.9710 - val_loss: 0.0853\n",
            "Epoch 29/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0845 - val_accuracy: 0.9704 - val_loss: 0.0862\n",
            "Epoch 30/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0849 - val_accuracy: 0.9709 - val_loss: 0.0851\n",
            "Epoch 31/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0842 - val_accuracy: 0.9712 - val_loss: 0.0848\n",
            "Epoch 32/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0839 - val_accuracy: 0.9711 - val_loss: 0.0852\n",
            "Epoch 33/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.0867 - val_accuracy: 0.9713 - val_loss: 0.0850\n",
            "Epoch 34/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0857 - val_accuracy: 0.9705 - val_loss: 0.0869\n",
            "Epoch 35/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0833 - val_accuracy: 0.9714 - val_loss: 0.0852\n",
            "Epoch 36/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0856 - val_accuracy: 0.9703 - val_loss: 0.0871\n",
            "Epoch 37/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0807 - val_accuracy: 0.9712 - val_loss: 0.0854\n",
            "Epoch 38/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0836 - val_accuracy: 0.9711 - val_loss: 0.0855\n",
            "Epoch 39/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0869 - val_accuracy: 0.9712 - val_loss: 0.0845\n",
            "Epoch 40/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.0839 - val_accuracy: 0.9713 - val_loss: 0.0847\n",
            "Epoch 41/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0847 - val_accuracy: 0.9712 - val_loss: 0.0850\n",
            "Epoch 42/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0859 - val_accuracy: 0.9711 - val_loss: 0.0849\n",
            "Epoch 43/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0845 - val_accuracy: 0.9712 - val_loss: 0.0854\n",
            "Epoch 44/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0837 - val_accuracy: 0.9712 - val_loss: 0.0853\n",
            "Epoch 45/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0827 - val_accuracy: 0.9709 - val_loss: 0.0857\n",
            "Epoch 46/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0860 - val_accuracy: 0.9709 - val_loss: 0.0853\n",
            "Epoch 47/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0855 - val_accuracy: 0.9709 - val_loss: 0.0852\n",
            "Epoch 48/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0848 - val_accuracy: 0.9712 - val_loss: 0.0854\n",
            "Epoch 49/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0820 - val_accuracy: 0.9696 - val_loss: 0.0875\n",
            "Epoch 50/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0865 - val_accuracy: 0.9711 - val_loss: 0.0851\n",
            "Epoch 51/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0846 - val_accuracy: 0.9711 - val_loss: 0.0848\n",
            "Epoch 52/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0850 - val_accuracy: 0.9712 - val_loss: 0.0851\n",
            "Epoch 53/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0857 - val_accuracy: 0.9709 - val_loss: 0.0858\n",
            "Epoch 54/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0838 - val_accuracy: 0.9712 - val_loss: 0.0850\n",
            "Epoch 55/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.0832 - val_accuracy: 0.9712 - val_loss: 0.0852\n",
            "Epoch 56/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0841 - val_accuracy: 0.9711 - val_loss: 0.0854\n",
            "Epoch 57/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0844 - val_accuracy: 0.9711 - val_loss: 0.0847\n",
            "Epoch 58/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0843 - val_accuracy: 0.9711 - val_loss: 0.0856\n",
            "Epoch 59/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0851 - val_accuracy: 0.9712 - val_loss: 0.0849\n",
            "Epoch 60/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0837 - val_accuracy: 0.9712 - val_loss: 0.0852\n",
            "Epoch 61/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0826 - val_accuracy: 0.9712 - val_loss: 0.0844\n",
            "Epoch 62/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9719 - loss: 0.0829 - val_accuracy: 0.9711 - val_loss: 0.0849\n",
            "Epoch 63/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0857 - val_accuracy: 0.9713 - val_loss: 0.0850\n",
            "Epoch 64/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0815 - val_accuracy: 0.9716 - val_loss: 0.0851\n",
            "Epoch 65/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0818 - val_accuracy: 0.9711 - val_loss: 0.0852\n",
            "Epoch 66/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0857 - val_accuracy: 0.9712 - val_loss: 0.0851\n",
            "Epoch 67/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0869 - val_accuracy: 0.9704 - val_loss: 0.0863\n",
            "Epoch 68/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0844 - val_accuracy: 0.9711 - val_loss: 0.0853\n",
            "Epoch 69/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0820 - val_accuracy: 0.9712 - val_loss: 0.0850\n",
            "Epoch 70/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9725 - loss: 0.0815 - val_accuracy: 0.9708 - val_loss: 0.0857\n",
            "Epoch 71/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0838 - val_accuracy: 0.9711 - val_loss: 0.0853\n",
            "Epoch 72/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.0823 - val_accuracy: 0.9706 - val_loss: 0.0869\n",
            "Epoch 73/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0840 - val_accuracy: 0.9710 - val_loss: 0.0857\n",
            "Epoch 74/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9706 - loss: 0.0857 - val_accuracy: 0.9711 - val_loss: 0.0850\n",
            "Epoch 75/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0823 - val_accuracy: 0.9712 - val_loss: 0.0852\n",
            "Epoch 76/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0836 - val_accuracy: 0.9712 - val_loss: 0.0850\n",
            "Epoch 77/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0843 - val_accuracy: 0.9713 - val_loss: 0.0851\n",
            "Epoch 78/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0852 - val_accuracy: 0.9712 - val_loss: 0.0852\n",
            "Epoch 79/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0823 - val_accuracy: 0.9714 - val_loss: 0.0857\n",
            "Epoch 80/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0824 - val_accuracy: 0.9712 - val_loss: 0.0854\n",
            "Epoch 81/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0854 - val_accuracy: 0.9712 - val_loss: 0.0857\n",
            "Epoch 82/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0820 - val_accuracy: 0.9712 - val_loss: 0.0857\n",
            "Epoch 83/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0852 - val_accuracy: 0.9713 - val_loss: 0.0851\n",
            "Epoch 84/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0837 - val_accuracy: 0.9712 - val_loss: 0.0851\n",
            "Epoch 85/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0844 - val_accuracy: 0.9712 - val_loss: 0.0853\n",
            "Epoch 86/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0848 - val_accuracy: 0.9712 - val_loss: 0.0846\n",
            "Epoch 87/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.0799 - val_accuracy: 0.9713 - val_loss: 0.0850\n",
            "Epoch 88/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0838 - val_accuracy: 0.9711 - val_loss: 0.0856\n",
            "Epoch 89/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0817 - val_accuracy: 0.9712 - val_loss: 0.0853\n",
            "Epoch 90/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0854 - val_accuracy: 0.9713 - val_loss: 0.0848\n",
            "Epoch 91/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0860 - val_accuracy: 0.9712 - val_loss: 0.0848\n",
            "Epoch 92/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0842 - val_accuracy: 0.9712 - val_loss: 0.0846\n",
            "Epoch 93/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0838 - val_accuracy: 0.9713 - val_loss: 0.0855\n",
            "Epoch 94/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.0839 - val_accuracy: 0.9712 - val_loss: 0.0852\n",
            "Epoch 95/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0852 - val_accuracy: 0.9712 - val_loss: 0.0846\n",
            "Epoch 96/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0827 - val_accuracy: 0.9712 - val_loss: 0.0847\n",
            "Epoch 97/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0850 - val_accuracy: 0.9711 - val_loss: 0.0858\n",
            "Epoch 98/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9724 - loss: 0.0825 - val_accuracy: 0.9712 - val_loss: 0.0851\n",
            "Epoch 99/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0828 - val_accuracy: 0.9712 - val_loss: 0.0851\n",
            "Epoch 100/100\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.0818 - val_accuracy: 0.9712 - val_loss: 0.0849\n"
          ]
        }
      ],
      "source": [
        "model1=Sequential()\n",
        "model1.add(Dense(units=64,input_dim= X_train_res.shape[1]))\n",
        "model1.add(LeakyReLU(alpha=0.01))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(units=32))\n",
        "model1.add(LeakyReLU(alpha=0.01))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(units=16))\n",
        "model1.add(LeakyReLU(alpha=0.01))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(units=1,activation='sigmoid'))\n",
        "optimizer=Adam(learning_rate=0.001)\n",
        "model1.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "#train the model\n",
        "model=model1.fit(X_train,y_train,epochs=100,batch_size=32,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p9XNOmjnqxQ",
        "outputId": "d100f3ae-6263-45b9-d216-d66df9a7841f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.97215"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred=model1.predict(X_test)\n",
        "y_pred_thresholded=(y_pred>0.5).astype(int)\n",
        "#making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "df=confusion_matrix(y_test,y_pred_thresholded)\n",
        "df\n",
        "#Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_test,y_pred_thresholded)\n",
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ask_iyoint5n",
        "outputId": "26a0ac0c-643c-493d-8162-6088ebfbca52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1031\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.0984\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.0994\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.0990\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.1006\n",
            "Epoch 6/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.0978\n",
            "Epoch 7/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.0963\n",
            "Epoch 8/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.0955\n",
            "Epoch 9/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.0943\n",
            "Epoch 10/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0892\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1cb23bedd60>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#model_history=classifier.fit(x_train,y_train,batch_size=10,epochs=100)\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping=EarlyStopping(monitor=\"loss\",patience=5,restore_best_weights=True)\n",
        "classifier.fit(X_train,y_train,epochs=10,callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['diabetes_model.pkl']"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'diabetes_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9721\n",
            "Precision: 0.9991\n",
            "Recall: 0.6745\n",
            "F1 Score: 0.8053\n",
            "ROC-AUC Score: 0.9769\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_thresholded)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test, y_pred_thresholded)\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test, y_pred_thresholded)\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test, y_pred_thresholded)\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# ROC-AUC (use raw probabilities from model1.predict)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1485\n",
            "Epoch 2/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9643 - loss: 0.1035\n",
            "Epoch 3/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9676 - loss: 0.0942\n",
            "Epoch 4/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.0910\n",
            "Epoch 5/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0906\n",
            "Epoch 6/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9703 - loss: 0.0874\n",
            "Epoch 7/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0872\n",
            "Epoch 8/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0864\n",
            "Epoch 9/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0841\n",
            "Epoch 10/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0851\n",
            "Epoch 11/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0882\n",
            "Epoch 12/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0863\n",
            "Epoch 13/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0862\n",
            "Epoch 14/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.0822\n",
            "Epoch 15/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0841\n",
            "Epoch 16/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.0839\n",
            "Epoch 17/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0824\n",
            "Epoch 18/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0852\n",
            "Epoch 19/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.0855\n",
            "Epoch 20/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0842\n",
            "Epoch 21/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0830\n",
            "Epoch 22/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0834\n",
            "Epoch 23/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0851\n",
            "Epoch 24/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0816\n",
            "Epoch 25/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0844\n",
            "Epoch 26/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0855\n",
            "Epoch 27/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0836\n",
            "Epoch 28/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0836\n",
            "Epoch 29/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0861\n",
            "Epoch 30/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0824\n",
            "Epoch 31/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.0837\n",
            "Epoch 32/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.0834\n",
            "Epoch 33/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.9711 - loss: 0.0857\n",
            "Epoch 34/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0838\n",
            "Epoch 35/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0828\n",
            "Epoch 36/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0846\n",
            "Epoch 37/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0841\n",
            "Epoch 38/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0825\n",
            "Epoch 39/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0824\n",
            "Epoch 40/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0824\n",
            "Epoch 41/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0835\n",
            "Epoch 42/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9706 - loss: 0.0853\n",
            "Epoch 43/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0827\n",
            "Epoch 44/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0835\n",
            "Epoch 45/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0833\n",
            "Epoch 46/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0837\n",
            "Epoch 47/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0857\n",
            "Epoch 48/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0794\n",
            "Epoch 49/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0841\n",
            "Epoch 50/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0833\n",
            "Epoch 51/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0834\n",
            "Epoch 52/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0824\n",
            "Epoch 53/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0838\n",
            "Epoch 54/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0828\n",
            "Epoch 55/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0817\n",
            "Epoch 56/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0821\n",
            "Epoch 57/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0848\n",
            "Epoch 58/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0836\n",
            "Epoch 59/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0826\n",
            "Epoch 60/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0847\n",
            "Epoch 61/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.0819\n",
            "Epoch 62/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0837\n",
            "Epoch 63/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0832\n",
            "Epoch 64/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0836\n",
            "Epoch 65/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.0833\n",
            "Epoch 66/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0829\n",
            "Epoch 67/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0822\n",
            "Epoch 68/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0839\n",
            "Epoch 69/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0823\n",
            "Epoch 70/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0832\n",
            "Epoch 71/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.0822\n",
            "Epoch 72/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0823\n",
            "Epoch 73/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.0814\n",
            "Epoch 74/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0827\n",
            "Epoch 75/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9727 - loss: 0.0805\n",
            "Epoch 76/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.0831\n",
            "Epoch 77/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0833\n",
            "Epoch 78/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0827\n",
            "Epoch 79/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0808\n",
            "Epoch 80/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0830\n",
            "Epoch 81/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0836\n",
            "Epoch 82/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0839\n",
            "Epoch 83/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.0838\n",
            "Epoch 84/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.0805\n",
            "Epoch 85/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0813\n",
            "Epoch 86/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0825\n",
            "Epoch 87/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0839\n",
            "Epoch 88/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0824\n",
            "Epoch 89/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9719 - loss: 0.0810\n",
            "Epoch 90/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.0795\n",
            "Epoch 91/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.0835\n",
            "Epoch 92/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0828\n",
            "Epoch 93/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0806\n",
            "Epoch 94/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.0817\n",
            "Epoch 95/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0826\n",
            "Epoch 96/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0815\n",
            "Epoch 97/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.0826\n",
            "Epoch 98/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0811\n",
            "Epoch 99/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0812\n",
            "Epoch 100/100\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"diabetes_prediction_dataset.csv\")\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Save encoders\n",
        "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
        "\n",
        "X = df.drop('diabetes', axis=1)\n",
        "y = df['diabetes']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build ANN model\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
        "\n",
        "# Save model\n",
        "model.save(\"diabetes_ann_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "python train_model.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
